{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043897,
     "end_time": "2020-11-05T22:44:37.103837",
     "exception": false,
     "start_time": "2020-11-05T22:44:37.059940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color: white; background: #ADD8E6; text-align:center; font-size: 2.3em;\"> MoA + Feature Engeneering + Keras </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042474,
     "end_time": "2020-11-05T22:44:37.188859",
     "exception": false,
     "start_time": "2020-11-05T22:44:37.146385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2f757229-7f7b-4ea6-b69a-270249d85727",
    "_uuid": "c014d6b0-3b76-46e4-a18f-de3d38f0ad9c",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:44:37.283548Z",
     "iopub.status.busy": "2020-11-05T22:44:37.282436Z",
     "iopub.status.idle": "2020-11-05T22:44:37.293945Z",
     "shell.execute_reply": "2020-11-05T22:44:37.294518Z"
    },
    "papermill": {
     "duration": 0.062803,
     "end_time": "2020-11-05T22:44:37.294669",
     "exception": false,
     "start_time": "2020-11-05T22:44:37.231866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-1.2.0-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\n",
      "/kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.1-py3-none-any.whl\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/rank-gauss/rankGaussTrafo.py\n",
      "/kaggle/input/rank-gauss/rgn.py\n",
      "/kaggle/input/rank-gauss/gauss_rank_scaler.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04137,
     "end_time": "2020-11-05T22:44:37.378052",
     "exception": false,
     "start_time": "2020-11-05T22:44:37.336682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:44:37.481449Z",
     "iopub.status.busy": "2020-11-05T22:44:37.480187Z",
     "iopub.status.idle": "2020-11-05T22:44:47.099462Z",
     "shell.execute_reply": "2020-11-05T22:44:47.098208Z"
    },
    "papermill": {
     "duration": 9.679455,
     "end_time": "2020-11-05T22:44:47.099602",
     "exception": false,
     "start_time": "2020-11-05T22:44:37.420147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.18.5)\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (0.23.2)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.6.0)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (4.45.0)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet) (1.4.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (0.14.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045425,
     "end_time": "2020-11-05T22:44:47.191905",
     "exception": false,
     "start_time": "2020-11-05T22:44:47.146480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "99fa0530-d4cf-4803-9596-060a6980270b",
    "_uuid": "d4ba5f02-0fe6-4210-93a0-818ff7614bd6",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:44:47.301671Z",
     "iopub.status.busy": "2020-11-05T22:44:47.300393Z",
     "iopub.status.idle": "2020-11-05T22:44:54.947768Z",
     "shell.execute_reply": "2020-11-05T22:44:54.946446Z"
    },
    "papermill": {
     "duration": 7.709605,
     "end_time": "2020-11-05T22:44:54.947931",
     "exception": false,
     "start_time": "2020-11-05T22:44:47.238326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Keras and Tf ##\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.callbacks as C\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.optimizers as O\n",
    "import tensorflow.keras.utils as U\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#Utils\n",
    "\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "## Preprocessing and sklearn ##\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "sys.path.append('../input/rank-gauss')\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "## Pytorch ##\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "## TabNet\n",
    "sys.path.append('../input/pytorch-tabnet')\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046737,
     "end_time": "2020-11-05T22:44:55.043569",
     "exception": false,
     "start_time": "2020-11-05T22:44:54.996832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2 Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "4523fe40-9241-427d-9054-391f9107ee80",
    "_uuid": "e5ebde3e-8733-4f43-9bd5-87942b293715",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:44:55.144399Z",
     "iopub.status.busy": "2020-11-05T22:44:55.143345Z",
     "iopub.status.idle": "2020-11-05T22:45:01.177214Z",
     "shell.execute_reply": "2020-11-05T22:45:01.176473Z"
    },
    "papermill": {
     "duration": 6.087253,
     "end_time": "2020-11-05T22:45:01.177351",
     "exception": false,
     "start_time": "2020-11-05T22:44:55.090098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sub = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "becd92fe-dbbe-4af0-bd33-3d5706f367a4",
    "_uuid": "2c5892c4-f2d9-430d-b986-4d9519e5e9f8",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:01.286351Z",
     "iopub.status.busy": "2020-11-05T22:45:01.285400Z",
     "iopub.status.idle": "2020-11-05T22:45:01.341723Z",
     "shell.execute_reply": "2020-11-05T22:45:01.341026Z"
    },
    "papermill": {
     "duration": 0.116231,
     "end_time": "2020-11-05T22:45:01.341876",
     "exception": false,
     "start_time": "2020-11-05T22:45:01.225645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>-0.8121</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>-0.3246</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.8086</td>\n",
       "      <td>-0.9798</td>\n",
       "      <td>-0.2084</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>-0.2715</td>\n",
       "      <td>0.3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.7592</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1105</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>-0.2012</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>1.5230</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>-0.6290</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3890</td>\n",
       "      <td>-1.7450</td>\n",
       "      <td>-6.6300</td>\n",
       "      <td>-4.0950</td>\n",
       "      <td>-7.3860</td>\n",
       "      <td>-1.4160</td>\n",
       "      <td>-3.5770</td>\n",
       "      <td>-0.4775</td>\n",
       "      <td>-2.1500</td>\n",
       "      <td>-4.2520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...      ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912   \n",
       "1      0.0604  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240   \n",
       "3      0.5288  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632   \n",
       "4      0.6919  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ...  0.1969  0.0262 -0.8121  0.3434  0.5372   \n",
       "23810  0.9905 -0.7178  0.6621  ...  0.4286  0.4426  0.0423 -0.3195 -0.8086   \n",
       "23811 -0.7389  0.5505 -0.0159  ...  0.5409  0.3755  0.7343  0.2807  0.4116   \n",
       "23812  0.2044  0.8531 -0.0343  ... -0.1105  0.4258 -0.2012  0.1506  1.5230   \n",
       "23813  0.7952 -0.3611 -3.6750  ... -3.3890 -1.7450 -6.6300 -4.0950 -7.3860   \n",
       "\n",
       "         c-95    c-96    c-97    c-98    c-99  \n",
       "0      0.6584 -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.4899  0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4     -0.3031  0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...     ...  \n",
       "23809 -0.3246  0.0631  0.9171  0.5258  0.4680  \n",
       "23810 -0.9798 -0.2084 -0.1224 -0.2715  0.3689  \n",
       "23811  0.6422  0.2256  0.7592  0.6656  0.3808  \n",
       "23812  0.7101  0.1732  0.7015 -0.6290  0.0740  \n",
       "23813 -1.4160 -3.5770 -0.4775 -2.1500 -4.2520  \n",
       "\n",
       "[23814 rows x 876 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "73558070-5142-4ddd-89cd-b86e4cd4a75a",
    "_uuid": "42ad87cf-23cc-469e-a95f-6aad1c77e47d",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:01.458198Z",
     "iopub.status.busy": "2020-11-05T22:45:01.457353Z",
     "iopub.status.idle": "2020-11-05T22:45:01.462611Z",
     "shell.execute_reply": "2020-11-05T22:45:01.461874Z"
    },
    "papermill": {
     "duration": 0.064807,
     "end_time": "2020-11-05T22:45:01.462757",
     "exception": false,
     "start_time": "2020-11-05T22:45:01.397950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = sub.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053811,
     "end_time": "2020-11-05T22:45:01.571281",
     "exception": false,
     "start_time": "2020-11-05T22:45:01.517470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3 Set Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "9e4edee3-e66d-4d7f-8867-14c9711a1266",
    "_uuid": "7a82bf16-66c0-4ca9-9a3d-1ba945de3a15",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:01.687487Z",
     "iopub.status.busy": "2020-11-05T22:45:01.685828Z",
     "iopub.status.idle": "2020-11-05T22:45:01.688775Z",
     "shell.execute_reply": "2020-11-05T22:45:01.689318Z"
    },
    "papermill": {
     "duration": 0.063494,
     "end_time": "2020-11-05T22:45:01.689439",
     "exception": false,
     "start_time": "2020-11-05T22:45:01.625945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed67160f-0448-4809-b3ee-540f0e1d16b6",
    "_uuid": "e7da134b-a5a3-4529-bcac-8fcf8294772c",
    "papermill": {
     "duration": 0.048785,
     "end_time": "2020-11-05T22:45:01.787187",
     "exception": false,
     "start_time": "2020-11-05T22:45:01.738402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Feature Engineering/Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048594,
     "end_time": "2020-11-05T22:45:01.885226",
     "exception": false,
     "start_time": "2020-11-05T22:45:01.836632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1 Remove Control Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:01.997778Z",
     "iopub.status.busy": "2020-11-05T22:45:01.996782Z",
     "iopub.status.idle": "2020-11-05T22:45:02.079830Z",
     "shell.execute_reply": "2020-11-05T22:45:02.079182Z"
    },
    "papermill": {
     "duration": 0.144928,
     "end_time": "2020-11-05T22:45:02.079961",
     "exception": false,
     "start_time": "2020-11-05T22:45:01.935033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove control group\n",
    "train_features = train_features[train_features[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "test_features = test_features[test_features[\"cp_type\"] != \"ctl_vehicle\"]\n",
    "train_targets = train_targets.iloc[train_features.index]\n",
    "train_features.reset_index(drop = True, inplace = True)\n",
    "test_features.reset_index(drop = True, inplace = True)\n",
    "train_targets.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050175,
     "end_time": "2020-11-05T22:45:02.181620",
     "exception": false,
     "start_time": "2020-11-05T22:45:02.131445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "877fb689-3259-43ce-87e1-f65ff61aee09",
    "_uuid": "7be02bf6-72ed-4853-987f-edb015922493",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:02.341387Z",
     "iopub.status.busy": "2020-11-05T22:45:02.293776Z",
     "iopub.status.idle": "2020-11-05T22:45:02.604218Z",
     "shell.execute_reply": "2020-11-05T22:45:02.605260Z"
    },
    "papermill": {
     "duration": 0.373035,
     "end_time": "2020-11-05T22:45:02.605437",
     "exception": false,
     "start_time": "2020-11-05T22:45:02.232402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Feature Selection with Variance Threshold\n",
    "# #Had problems with submission on this\n",
    "c_n = [f for f in list(train_features.columns) if f not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]\n",
    "mask = (train_features[c_n].var() >= 0.7).values\n",
    "tmp = train_features[c_n].loc[:, mask]\n",
    "train_features = pd.concat([train_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)\n",
    "tmp = test_features[c_n].loc[:, mask]\n",
    "test_features = pd.concat([test_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049922,
     "end_time": "2020-11-05T22:45:02.705828",
     "exception": false,
     "start_time": "2020-11-05T22:45:02.655906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "25a30a96-a61b-488e-afc3-b673fc00c525",
    "_uuid": "e56a0dcf-057b-496a-88cf-dd405ba00af9",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:02.818373Z",
     "iopub.status.busy": "2020-11-05T22:45:02.816422Z",
     "iopub.status.idle": "2020-11-05T22:45:02.819232Z",
     "shell.execute_reply": "2020-11-05T22:45:02.819793Z"
    },
    "papermill": {
     "duration": 0.065212,
     "end_time": "2020-11-05T22:45:02.819931",
     "exception": false,
     "start_time": "2020-11-05T22:45:02.754719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We are actully adding the feature from the pca into the original data in here, it helps the score for some reason\n",
    "def pca(train, test, n_comp = 55, type_ = \"\", SEED = 123):\n",
    "    \n",
    "    kind = \"g\" if type_ == GENES else \"c\"\n",
    "    data = pd.concat([train[type_], test[type_]])\n",
    "#     train.drop(type_, axis = 1, inplace = True)\n",
    "#     test.drop(type_, axis = 1, inplace = True)\n",
    "    pca = PCA(n_components= n_comp, random_state = SEED)\n",
    "    data = pd.DataFrame(pca.fit_transform(data), columns = [f'pca-{kind}-{i + 1}' for i in range(n_comp)])\n",
    "    train_ = data.iloc[:train.shape[0]]\n",
    "    test_ = data.iloc[train.shape[0]:].reset_index(drop = True)\n",
    "    train = pd.concat([train, train_], axis = 1)\n",
    "    test = pd.concat([test, test_], axis = 1)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:02.930045Z",
     "iopub.status.busy": "2020-11-05T22:45:02.929232Z",
     "iopub.status.idle": "2020-11-05T22:45:02.933888Z",
     "shell.execute_reply": "2020-11-05T22:45:02.933325Z"
    },
    "papermill": {
     "duration": 0.061346,
     "end_time": "2020-11-05T22:45:02.934002",
     "exception": false,
     "start_time": "2020-11-05T22:45:02.872656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#All the col that has genes and cells\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "167eb790-c44c-488a-a5d8-00a631765427",
    "_uuid": "3396e928-9df2-41af-8c35-b07880c3a179",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:03.044772Z",
     "iopub.status.busy": "2020-11-05T22:45:03.043163Z",
     "iopub.status.idle": "2020-11-05T22:45:06.415929Z",
     "shell.execute_reply": "2020-11-05T22:45:06.414499Z"
    },
    "papermill": {
     "duration": 3.430949,
     "end_time": "2020-11-05T22:45:06.416081",
     "exception": false,
     "start_time": "2020-11-05T22:45:02.985132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features, test_features = pca(train_features, test_features, n_comp = 120, type_ = GENES)\n",
    "train_features, test_features = pca(train_features, test_features, n_comp = 20, type_ = CELLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:06.547560Z",
     "iopub.status.busy": "2020-11-05T22:45:06.522784Z",
     "iopub.status.idle": "2020-11-05T22:45:06.577566Z",
     "shell.execute_reply": "2020-11-05T22:45:06.578180Z"
    },
    "papermill": {
     "duration": 0.112452,
     "end_time": "2020-11-05T22:45:06.578339",
     "exception": false,
     "start_time": "2020-11-05T22:45:06.465887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>pca-c-11</th>\n",
       "      <th>pca-c-12</th>\n",
       "      <th>pca-c-13</th>\n",
       "      <th>pca-c-14</th>\n",
       "      <th>pca-c-15</th>\n",
       "      <th>pca-c-16</th>\n",
       "      <th>pca-c-17</th>\n",
       "      <th>pca-c-18</th>\n",
       "      <th>pca-c-19</th>\n",
       "      <th>pca-c-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687773</td>\n",
       "      <td>-0.551501</td>\n",
       "      <td>-0.576611</td>\n",
       "      <td>-0.081799</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>-0.889118</td>\n",
       "      <td>-1.019991</td>\n",
       "      <td>-0.293436</td>\n",
       "      <td>-0.827717</td>\n",
       "      <td>-0.569132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820746</td>\n",
       "      <td>-0.173563</td>\n",
       "      <td>0.728606</td>\n",
       "      <td>0.250554</td>\n",
       "      <td>1.205988</td>\n",
       "      <td>-0.536938</td>\n",
       "      <td>0.840609</td>\n",
       "      <td>-0.021688</td>\n",
       "      <td>0.218566</td>\n",
       "      <td>0.292075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217845</td>\n",
       "      <td>0.178157</td>\n",
       "      <td>0.415141</td>\n",
       "      <td>0.494522</td>\n",
       "      <td>-0.435289</td>\n",
       "      <td>0.893302</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>1.046894</td>\n",
       "      <td>0.082787</td>\n",
       "      <td>0.789685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039129</td>\n",
       "      <td>0.144012</td>\n",
       "      <td>0.878549</td>\n",
       "      <td>-1.351130</td>\n",
       "      <td>1.604516</td>\n",
       "      <td>0.233892</td>\n",
       "      <td>0.639763</td>\n",
       "      <td>-0.375438</td>\n",
       "      <td>1.440603</td>\n",
       "      <td>1.366497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105938</td>\n",
       "      <td>-0.255500</td>\n",
       "      <td>0.175404</td>\n",
       "      <td>-0.016431</td>\n",
       "      <td>-0.772789</td>\n",
       "      <td>0.425729</td>\n",
       "      <td>0.391218</td>\n",
       "      <td>0.121719</td>\n",
       "      <td>0.660142</td>\n",
       "      <td>-0.449516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860570</td>\n",
       "      <td>0.779536</td>\n",
       "      <td>-0.072007</td>\n",
       "      <td>0.329810</td>\n",
       "      <td>-0.058445</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>-0.019420</td>\n",
       "      <td>0.898136</td>\n",
       "      <td>0.302271</td>\n",
       "      <td>-0.174918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305824</td>\n",
       "      <td>0.780934</td>\n",
       "      <td>-0.242487</td>\n",
       "      <td>-0.132851</td>\n",
       "      <td>0.948908</td>\n",
       "      <td>0.631465</td>\n",
       "      <td>0.698903</td>\n",
       "      <td>-0.791345</td>\n",
       "      <td>0.653110</td>\n",
       "      <td>0.196764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245729</td>\n",
       "      <td>0.718856</td>\n",
       "      <td>-0.561454</td>\n",
       "      <td>0.453753</td>\n",
       "      <td>0.168263</td>\n",
       "      <td>0.059555</td>\n",
       "      <td>0.487017</td>\n",
       "      <td>-0.254938</td>\n",
       "      <td>0.079887</td>\n",
       "      <td>-0.622716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>-1.690100</td>\n",
       "      <td>-0.309677</td>\n",
       "      <td>-0.166884</td>\n",
       "      <td>0.761904</td>\n",
       "      <td>-0.164638</td>\n",
       "      <td>-0.464094</td>\n",
       "      <td>0.808345</td>\n",
       "      <td>-0.334289</td>\n",
       "      <td>-0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025580</td>\n",
       "      <td>-0.533213</td>\n",
       "      <td>4.412461</td>\n",
       "      <td>2.285017</td>\n",
       "      <td>-1.133058</td>\n",
       "      <td>-0.721739</td>\n",
       "      <td>3.139823</td>\n",
       "      <td>0.546234</td>\n",
       "      <td>0.731652</td>\n",
       "      <td>2.584379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 983 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_type  cp_time cp_dose     g-0     g-2     g-3     g-4  \\\n",
       "0      id_000644bb2  trt_cp       24      D1  1.0620 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc  trt_cp       72      D1  0.0743  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a  trt_cp       48      D1  0.6280  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391  trt_cp       48      D1 -0.5138 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3  trt_cp       72      D2 -0.3254  0.9700  0.6919  1.4180   \n",
       "...             ...     ...      ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444  trt_cp       72      D1  0.1608  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed  trt_cp       24      D2  0.1394 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c  trt_cp       24      D2 -1.3260 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c  trt_cp       24      D1  0.6660  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b  trt_cp       72      D1 -0.8598 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "          g-5     g-6  ...  pca-c-11  pca-c-12  pca-c-13  pca-c-14  pca-c-15  \\\n",
       "0     -1.0120 -1.0220  ...  0.687773 -0.551501 -0.576611 -0.081799  0.527897   \n",
       "1      0.5207  0.2341  ...  0.820746 -0.173563  0.728606  0.250554  1.205988   \n",
       "2      1.2390  0.1715  ... -0.217845  0.178157  0.415141  0.494522 -0.435289   \n",
       "3     -0.8095 -1.9590  ... -0.039129  0.144012  0.878549 -1.351130  1.604516   \n",
       "4     -0.8244 -0.2800  ... -0.105938 -0.255500  0.175404 -0.016431 -0.772789   \n",
       "...       ...     ...  ...       ...       ...       ...       ...       ...   \n",
       "21943  0.4256 -0.1166  ... -0.860570  0.779536 -0.072007  0.329810 -0.058445   \n",
       "21944  0.7201  0.5773  ... -0.305824  0.780934 -0.242487 -0.132851  0.948908   \n",
       "21945  0.6621 -0.2252  ...  0.245729  0.718856 -0.561454  0.453753  0.168263   \n",
       "21946 -0.0343  0.0323  ...  0.808229 -1.690100 -0.309677 -0.166884  0.761904   \n",
       "21947 -3.6750 -1.2420  ... -0.025580 -0.533213  4.412461  2.285017 -1.133058   \n",
       "\n",
       "       pca-c-16  pca-c-17  pca-c-18  pca-c-19  pca-c-20  \n",
       "0     -0.889118 -1.019991 -0.293436 -0.827717 -0.569132  \n",
       "1     -0.536938  0.840609 -0.021688  0.218566  0.292075  \n",
       "2      0.893302 -0.328090  1.046894  0.082787  0.789685  \n",
       "3      0.233892  0.639763 -0.375438  1.440603  1.366497  \n",
       "4      0.425729  0.391218  0.121719  0.660142 -0.449516  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "21943  0.725834 -0.019420  0.898136  0.302271 -0.174918  \n",
       "21944  0.631465  0.698903 -0.791345  0.653110  0.196764  \n",
       "21945  0.059555  0.487017 -0.254938  0.079887 -0.622716  \n",
       "21946 -0.164638 -0.464094  0.808345 -0.334289 -0.019326  \n",
       "21947 -0.721739  3.139823  0.546234  0.731652  2.584379  \n",
       "\n",
       "[21948 rows x 983 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:06.697208Z",
     "iopub.status.busy": "2020-11-05T22:45:06.696449Z",
     "iopub.status.idle": "2020-11-05T22:45:06.700952Z",
     "shell.execute_reply": "2020-11-05T22:45:06.700380Z"
    },
    "papermill": {
     "duration": 0.066346,
     "end_time": "2020-11-05T22:45:06.701067",
     "exception": false,
     "start_time": "2020-11-05T22:45:06.634721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#All the col that has genes and cells\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "cols_numeric = [feat for feat in list(train_features.columns) if feat not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:06.808670Z",
     "iopub.status.busy": "2020-11-05T22:45:06.807679Z",
     "iopub.status.idle": "2020-11-05T22:45:06.854128Z",
     "shell.execute_reply": "2020-11-05T22:45:06.854712Z"
    },
    "papermill": {
     "duration": 0.104779,
     "end_time": "2020-11-05T22:45:06.854878",
     "exception": false,
     "start_time": "2020-11-05T22:45:06.750099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>pca-c-11</th>\n",
       "      <th>pca-c-12</th>\n",
       "      <th>pca-c-13</th>\n",
       "      <th>pca-c-14</th>\n",
       "      <th>pca-c-15</th>\n",
       "      <th>pca-c-16</th>\n",
       "      <th>pca-c-17</th>\n",
       "      <th>pca-c-18</th>\n",
       "      <th>pca-c-19</th>\n",
       "      <th>pca-c-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687773</td>\n",
       "      <td>-0.551501</td>\n",
       "      <td>-0.576611</td>\n",
       "      <td>-0.081799</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>-0.889118</td>\n",
       "      <td>-1.019991</td>\n",
       "      <td>-0.293436</td>\n",
       "      <td>-0.827717</td>\n",
       "      <td>-0.569132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820746</td>\n",
       "      <td>-0.173563</td>\n",
       "      <td>0.728606</td>\n",
       "      <td>0.250554</td>\n",
       "      <td>1.205988</td>\n",
       "      <td>-0.536938</td>\n",
       "      <td>0.840609</td>\n",
       "      <td>-0.021688</td>\n",
       "      <td>0.218566</td>\n",
       "      <td>0.292075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217845</td>\n",
       "      <td>0.178157</td>\n",
       "      <td>0.415141</td>\n",
       "      <td>0.494522</td>\n",
       "      <td>-0.435289</td>\n",
       "      <td>0.893302</td>\n",
       "      <td>-0.328090</td>\n",
       "      <td>1.046894</td>\n",
       "      <td>0.082787</td>\n",
       "      <td>0.789685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039129</td>\n",
       "      <td>0.144012</td>\n",
       "      <td>0.878549</td>\n",
       "      <td>-1.351130</td>\n",
       "      <td>1.604516</td>\n",
       "      <td>0.233892</td>\n",
       "      <td>0.639763</td>\n",
       "      <td>-0.375438</td>\n",
       "      <td>1.440603</td>\n",
       "      <td>1.366497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105938</td>\n",
       "      <td>-0.255500</td>\n",
       "      <td>0.175404</td>\n",
       "      <td>-0.016431</td>\n",
       "      <td>-0.772789</td>\n",
       "      <td>0.425729</td>\n",
       "      <td>0.391218</td>\n",
       "      <td>0.121719</td>\n",
       "      <td>0.660142</td>\n",
       "      <td>-0.449516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>-0.2431</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>-0.1166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860570</td>\n",
       "      <td>0.779536</td>\n",
       "      <td>-0.072007</td>\n",
       "      <td>0.329810</td>\n",
       "      <td>-0.058445</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>-0.019420</td>\n",
       "      <td>0.898136</td>\n",
       "      <td>0.302271</td>\n",
       "      <td>-0.174918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305824</td>\n",
       "      <td>0.780934</td>\n",
       "      <td>-0.242487</td>\n",
       "      <td>-0.132851</td>\n",
       "      <td>0.948908</td>\n",
       "      <td>0.631465</td>\n",
       "      <td>0.698903</td>\n",
       "      <td>-0.791345</td>\n",
       "      <td>0.653110</td>\n",
       "      <td>0.196764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>-0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245729</td>\n",
       "      <td>0.718856</td>\n",
       "      <td>-0.561454</td>\n",
       "      <td>0.453753</td>\n",
       "      <td>0.168263</td>\n",
       "      <td>0.059555</td>\n",
       "      <td>0.487017</td>\n",
       "      <td>-0.254938</td>\n",
       "      <td>0.079887</td>\n",
       "      <td>-0.622716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>-1.690100</td>\n",
       "      <td>-0.309677</td>\n",
       "      <td>-0.166884</td>\n",
       "      <td>0.761904</td>\n",
       "      <td>-0.164638</td>\n",
       "      <td>-0.464094</td>\n",
       "      <td>0.808345</td>\n",
       "      <td>-0.334289</td>\n",
       "      <td>-0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>-1.2420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025580</td>\n",
       "      <td>-0.533213</td>\n",
       "      <td>4.412461</td>\n",
       "      <td>2.285017</td>\n",
       "      <td>-1.133058</td>\n",
       "      <td>-0.721739</td>\n",
       "      <td>3.139823</td>\n",
       "      <td>0.546234</td>\n",
       "      <td>0.731652</td>\n",
       "      <td>2.584379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 983 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_type  cp_time cp_dose     g-0     g-2     g-3     g-4  \\\n",
       "0      id_000644bb2  trt_cp       24      D1  1.0620 -0.2479 -0.6208 -0.1944   \n",
       "1      id_000779bfc  trt_cp       72      D1  0.0743  0.2991  0.0604  1.0190   \n",
       "2      id_000a6266a  trt_cp       48      D1  0.6280  1.5540 -0.0764 -0.0323   \n",
       "3      id_0015fd391  trt_cp       48      D1 -0.5138 -0.2656  0.5288  4.0620   \n",
       "4      id_001626bd3  trt_cp       72      D2 -0.3254  0.9700  0.6919  1.4180   \n",
       "...             ...     ...      ...     ...     ...     ...     ...     ...   \n",
       "21943  id_fff8c2444  trt_cp       72      D1  0.1608  0.2551 -0.2239 -0.2431   \n",
       "21944  id_fffb1ceed  trt_cp       24      D2  0.1394 -0.1112 -0.5080 -0.4713   \n",
       "21945  id_fffb70c0c  trt_cp       24      D2 -1.3260 -0.3743  0.9905 -0.7178   \n",
       "21946  id_fffcb9e7c  trt_cp       24      D1  0.6660  0.4392  0.2044  0.8531   \n",
       "21947  id_ffffdd77b  trt_cp       72      D1 -0.8598 -0.1361  0.7952 -0.3611   \n",
       "\n",
       "          g-5     g-6  ...  pca-c-11  pca-c-12  pca-c-13  pca-c-14  pca-c-15  \\\n",
       "0     -1.0120 -1.0220  ...  0.687773 -0.551501 -0.576611 -0.081799  0.527897   \n",
       "1      0.5207  0.2341  ...  0.820746 -0.173563  0.728606  0.250554  1.205988   \n",
       "2      1.2390  0.1715  ... -0.217845  0.178157  0.415141  0.494522 -0.435289   \n",
       "3     -0.8095 -1.9590  ... -0.039129  0.144012  0.878549 -1.351130  1.604516   \n",
       "4     -0.8244 -0.2800  ... -0.105938 -0.255500  0.175404 -0.016431 -0.772789   \n",
       "...       ...     ...  ...       ...       ...       ...       ...       ...   \n",
       "21943  0.4256 -0.1166  ... -0.860570  0.779536 -0.072007  0.329810 -0.058445   \n",
       "21944  0.7201  0.5773  ... -0.305824  0.780934 -0.242487 -0.132851  0.948908   \n",
       "21945  0.6621 -0.2252  ...  0.245729  0.718856 -0.561454  0.453753  0.168263   \n",
       "21946 -0.0343  0.0323  ...  0.808229 -1.690100 -0.309677 -0.166884  0.761904   \n",
       "21947 -3.6750 -1.2420  ... -0.025580 -0.533213  4.412461  2.285017 -1.133058   \n",
       "\n",
       "       pca-c-16  pca-c-17  pca-c-18  pca-c-19  pca-c-20  \n",
       "0     -0.889118 -1.019991 -0.293436 -0.827717 -0.569132  \n",
       "1     -0.536938  0.840609 -0.021688  0.218566  0.292075  \n",
       "2      0.893302 -0.328090  1.046894  0.082787  0.789685  \n",
       "3      0.233892  0.639763 -0.375438  1.440603  1.366497  \n",
       "4      0.425729  0.391218  0.121719  0.660142 -0.449516  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "21943  0.725834 -0.019420  0.898136  0.302271 -0.174918  \n",
       "21944  0.631465  0.698903 -0.791345  0.653110  0.196764  \n",
       "21945  0.059555  0.487017 -0.254938  0.079887 -0.622716  \n",
       "21946 -0.164638 -0.464094  0.808345 -0.334289 -0.019326  \n",
       "21947 -0.721739  3.139823  0.546234  0.731652  2.584379  \n",
       "\n",
       "[21948 rows x 983 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052468,
     "end_time": "2020-11-05T22:45:06.965373",
     "exception": false,
     "start_time": "2020-11-05T22:45:06.912905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4 Feature Creation using KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:07.080997Z",
     "iopub.status.busy": "2020-11-05T22:45:07.080022Z",
     "iopub.status.idle": "2020-11-05T22:45:07.083079Z",
     "shell.execute_reply": "2020-11-05T22:45:07.082521Z"
    },
    "papermill": {
     "duration": 0.065054,
     "end_time": "2020-11-05T22:45:07.083212",
     "exception": false,
     "start_time": "2020-11-05T22:45:07.018158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cluster(train, test, kind, n_cluster, str_kind):\n",
    "    \n",
    "    data = pd.concat([train[kind], test[kind]], ignore_index = True)\n",
    "    kmeans = KMeans(n_clusters = n_cluster, random_state = 0,).fit(data)\n",
    "    train[f'clusters_{str_kind}'] = kmeans.labels_[:train.shape[0]]\n",
    "    test[f'clusters_{str_kind}'] = kmeans.labels_[train.shape[0]:]\n",
    "    train = pd.get_dummies(train, columns = [f'clusters_{str_kind}'])\n",
    "    test = pd.get_dummies(test, columns = [f'clusters_{str_kind}'])\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:07.192898Z",
     "iopub.status.busy": "2020-11-05T22:45:07.191929Z",
     "iopub.status.idle": "2020-11-05T22:45:07.195251Z",
     "shell.execute_reply": "2020-11-05T22:45:07.194678Z"
    },
    "papermill": {
     "duration": 0.059143,
     "end_time": "2020-11-05T22:45:07.195358",
     "exception": false,
     "start_time": "2020-11-05T22:45:07.136215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_features, test_features = create_cluster(train_features, test_features, GENES, 35, \"g\")\n",
    "# train_features, test_features = create_cluster(train_features, test_features, CELLS, 5, \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:07.306699Z",
     "iopub.status.busy": "2020-11-05T22:45:07.305397Z",
     "iopub.status.idle": "2020-11-05T22:45:07.508452Z",
     "shell.execute_reply": "2020-11-05T22:45:07.507864Z"
    },
    "papermill": {
     "duration": 0.261327,
     "end_time": "2020-11-05T22:45:07.508618",
     "exception": false,
     "start_time": "2020-11-05T22:45:07.247291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train_features, test_features], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052261,
     "end_time": "2020-11-05T22:45:07.612515",
     "exception": false,
     "start_time": "2020-11-05T22:45:07.560254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.5 Gauss Rank Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "0d1b2d54-fc20-4004-adf2-52d1bb8e0caa",
    "_uuid": "7f6bb532-a385-43d9-81de-73c63aac330f",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:07.725027Z",
     "iopub.status.busy": "2020-11-05T22:45:07.724322Z",
     "iopub.status.idle": "2020-11-05T22:45:29.550693Z",
     "shell.execute_reply": "2020-11-05T22:45:29.549660Z"
    },
    "papermill": {
     "duration": 21.885165,
     "end_time": "2020-11-05T22:45:29.550837",
     "exception": false,
     "start_time": "2020-11-05T22:45:07.665672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "scaler = GaussRankScaler()\n",
    "data[cols_numeric]  = scaler.fit_transform(data[cols_numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052646,
     "end_time": "2020-11-05T22:45:29.654837",
     "exception": false,
     "start_time": "2020-11-05T22:45:29.602191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.6 Stats of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:29.768813Z",
     "iopub.status.busy": "2020-11-05T22:45:29.767397Z",
     "iopub.status.idle": "2020-11-05T22:45:33.872177Z",
     "shell.execute_reply": "2020-11-05T22:45:33.871525Z"
    },
    "papermill": {
     "duration": 4.165807,
     "end_time": "2020-11-05T22:45:33.872295",
     "exception": false,
     "start_time": "2020-11-05T22:45:29.706488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "for stats in tqdm.tqdm([\"mean\", \"std\", \"kurt\", \"skew\"]):\n",
    "    data[\"g_\" + stats] = getattr(data[GENES], stats)(axis = 1)\n",
    "    data[\"c_\" + stats] = getattr(data[CELLS], stats)(axis = 1)    \n",
    "    data[\"gc_\" + stats] = getattr(data[GENES + CELLS], stats)(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "de9aa3cb-01f0-4e29-b580-13286315aaa3",
    "_uuid": "2e587cf3-1478-4308-bbfc-5c5c1b4acade",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:33.989188Z",
     "iopub.status.busy": "2020-11-05T22:45:33.987796Z",
     "iopub.status.idle": "2020-11-05T22:45:34.051198Z",
     "shell.execute_reply": "2020-11-05T22:45:34.050535Z"
    },
    "papermill": {
     "duration": 0.124466,
     "end_time": "2020-11-05T22:45:34.051322",
     "exception": false,
     "start_time": "2020-11-05T22:45:33.926856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Spliting the data back into train and test\n",
    "train_features = data.iloc[:train_features.shape[0]].reset_index(drop = True)\n",
    "test_features = data.iloc[train_features.shape[0]:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054584,
     "end_time": "2020-11-05T22:45:34.162899",
     "exception": false,
     "start_time": "2020-11-05T22:45:34.108315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055739,
     "end_time": "2020-11-05T22:45:34.274064",
     "exception": false,
     "start_time": "2020-11-05T22:45:34.218325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.1 Get Dummies & Dropping sig_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "e81bae51-ad02-4047-87a5-cc786773b9c6",
    "_uuid": "ab77edfc-b403-46a2-9dcc-9857ab605f82",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:34.390452Z",
     "iopub.status.busy": "2020-11-05T22:45:34.389570Z",
     "iopub.status.idle": "2020-11-05T22:45:34.393902Z",
     "shell.execute_reply": "2020-11-05T22:45:34.393323Z"
    },
    "papermill": {
     "duration": 0.065881,
     "end_time": "2020-11-05T22:45:34.394007",
     "exception": false,
     "start_time": "2020-11-05T22:45:34.328126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(data, target=False):\n",
    "    data.drop(\"sig_id\", axis=1, inplace=True)\n",
    "    if target == False:\n",
    "        data[\"cp_dose_time\"] = data[\"cp_dose\"] + \"_\" + data[\"cp_time\"].astype(\"str\")\n",
    "        data[\"cp_dose_time\"] = data[\"cp_dose_time\"].map({\"D1_24\":0 , \"D1_48\":1, \"D1_72\":2, \"D2_24\":3 , \"D2_48\":4, \"D2_72\":5})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "27aa2178-9d1a-420f-a321-e95ddd73711f",
    "_uuid": "2d4ee019-392b-4a08-8432-c44b36c978a7",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:34.511788Z",
     "iopub.status.busy": "2020-11-05T22:45:34.510344Z",
     "iopub.status.idle": "2020-11-05T22:45:34.925637Z",
     "shell.execute_reply": "2020-11-05T22:45:34.925044Z"
    },
    "papermill": {
     "duration": 0.477909,
     "end_time": "2020-11-05T22:45:34.925784",
     "exception": false,
     "start_time": "2020-11-05T22:45:34.447875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = preprocess(train_features)\n",
    "train_targets = preprocess(train_targets, target=True)\n",
    "train_features = pd.get_dummies(train_features)\n",
    "test_features = preprocess(test_features)\n",
    "test_features = pd.get_dummies(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "ea9e975d-8a2e-4083-8cb5-015961864045",
    "_uuid": "fb1152ad-f4b3-4647-abcb-6c37d6d1304f",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:35.046300Z",
     "iopub.status.busy": "2020-11-05T22:45:35.045043Z",
     "iopub.status.idle": "2020-11-05T22:45:35.083534Z",
     "shell.execute_reply": "2020-11-05T22:45:35.084175Z"
    },
    "papermill": {
     "duration": 0.102143,
     "end_time": "2020-11-05T22:45:35.084321",
     "exception": false,
     "start_time": "2020-11-05T22:45:34.982178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>g-9</th>\n",
       "      <th>...</th>\n",
       "      <th>g_kurt</th>\n",
       "      <th>c_kurt</th>\n",
       "      <th>gc_kurt</th>\n",
       "      <th>g_skew</th>\n",
       "      <th>c_skew</th>\n",
       "      <th>gc_skew</th>\n",
       "      <th>cp_dose_time</th>\n",
       "      <th>cp_type_trt_cp</th>\n",
       "      <th>cp_dose_D1</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>0.731433</td>\n",
       "      <td>-0.254104</td>\n",
       "      <td>-0.615315</td>\n",
       "      <td>-0.194236</td>\n",
       "      <td>-0.772257</td>\n",
       "      <td>-1.061067</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>0.513989</td>\n",
       "      <td>-0.130963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.250230</td>\n",
       "      <td>-0.026184</td>\n",
       "      <td>-0.008259</td>\n",
       "      <td>0.118667</td>\n",
       "      <td>-0.036543</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>0.017020</td>\n",
       "      <td>0.213820</td>\n",
       "      <td>0.027107</td>\n",
       "      <td>0.849834</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.217779</td>\n",
       "      <td>0.363904</td>\n",
       "      <td>-0.298420</td>\n",
       "      <td>0.730029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053247</td>\n",
       "      <td>0.111352</td>\n",
       "      <td>-0.099643</td>\n",
       "      <td>0.096482</td>\n",
       "      <td>-0.043717</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0.462792</td>\n",
       "      <td>0.981712</td>\n",
       "      <td>-0.091777</td>\n",
       "      <td>-0.039121</td>\n",
       "      <td>1.055526</td>\n",
       "      <td>0.161005</td>\n",
       "      <td>0.242395</td>\n",
       "      <td>0.050070</td>\n",
       "      <td>0.975415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362998</td>\n",
       "      <td>-0.051865</td>\n",
       "      <td>-0.282383</td>\n",
       "      <td>-0.017658</td>\n",
       "      <td>0.379548</td>\n",
       "      <td>0.010043</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>-0.531916</td>\n",
       "      <td>-0.269127</td>\n",
       "      <td>0.455184</td>\n",
       "      <td>1.595325</td>\n",
       "      <td>-0.621171</td>\n",
       "      <td>-1.509230</td>\n",
       "      <td>0.206249</td>\n",
       "      <td>-0.066407</td>\n",
       "      <td>-0.889590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.880856</td>\n",
       "      <td>4.444686</td>\n",
       "      <td>-0.909214</td>\n",
       "      <td>0.108938</td>\n",
       "      <td>2.010409</td>\n",
       "      <td>0.273694</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>-0.341668</td>\n",
       "      <td>0.808567</td>\n",
       "      <td>0.604615</td>\n",
       "      <td>0.951946</td>\n",
       "      <td>-0.630950</td>\n",
       "      <td>-0.243933</td>\n",
       "      <td>-0.103294</td>\n",
       "      <td>-0.684346</td>\n",
       "      <td>0.741863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351803</td>\n",
       "      <td>-0.477550</td>\n",
       "      <td>-0.240858</td>\n",
       "      <td>-0.130955</td>\n",
       "      <td>0.191181</td>\n",
       "      <td>-0.201224</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>72</td>\n",
       "      <td>0.089366</td>\n",
       "      <td>0.176202</td>\n",
       "      <td>-0.226762</td>\n",
       "      <td>-0.244678</td>\n",
       "      <td>0.396468</td>\n",
       "      <td>-0.094758</td>\n",
       "      <td>-0.130161</td>\n",
       "      <td>-0.582338</td>\n",
       "      <td>0.056587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031021</td>\n",
       "      <td>-0.228406</td>\n",
       "      <td>-0.011154</td>\n",
       "      <td>-0.083142</td>\n",
       "      <td>0.473883</td>\n",
       "      <td>-0.017303</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>24</td>\n",
       "      <td>0.072056</td>\n",
       "      <td>-0.131998</td>\n",
       "      <td>-0.499092</td>\n",
       "      <td>-0.479222</td>\n",
       "      <td>0.667644</td>\n",
       "      <td>0.530397</td>\n",
       "      <td>0.333563</td>\n",
       "      <td>-0.356318</td>\n",
       "      <td>0.048109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196997</td>\n",
       "      <td>-0.145076</td>\n",
       "      <td>0.253493</td>\n",
       "      <td>-0.222104</td>\n",
       "      <td>0.367298</td>\n",
       "      <td>-0.168144</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>24</td>\n",
       "      <td>-1.346695</td>\n",
       "      <td>-0.369847</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>-0.735139</td>\n",
       "      <td>0.613056</td>\n",
       "      <td>-0.194656</td>\n",
       "      <td>-0.446960</td>\n",
       "      <td>0.479298</td>\n",
       "      <td>0.549999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102816</td>\n",
       "      <td>-0.157828</td>\n",
       "      <td>0.107293</td>\n",
       "      <td>-0.021382</td>\n",
       "      <td>0.484219</td>\n",
       "      <td>0.055402</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>24</td>\n",
       "      <td>0.490027</td>\n",
       "      <td>0.329593</td>\n",
       "      <td>0.157679</td>\n",
       "      <td>0.732402</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.034881</td>\n",
       "      <td>0.079245</td>\n",
       "      <td>0.405150</td>\n",
       "      <td>-0.742506</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.023389</td>\n",
       "      <td>-0.579405</td>\n",
       "      <td>-0.914582</td>\n",
       "      <td>-0.140780</td>\n",
       "      <td>0.200423</td>\n",
       "      <td>-0.189765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>72</td>\n",
       "      <td>-0.939748</td>\n",
       "      <td>-0.153659</td>\n",
       "      <td>0.695101</td>\n",
       "      <td>-0.365699</td>\n",
       "      <td>-1.352665</td>\n",
       "      <td>-1.150624</td>\n",
       "      <td>1.045868</td>\n",
       "      <td>1.472960</td>\n",
       "      <td>0.980444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861486</td>\n",
       "      <td>5.260566</td>\n",
       "      <td>-0.945209</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>1.850527</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 996 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cp_time       g-0       g-2       g-3       g-4       g-5       g-6  \\\n",
       "0           24  0.731433 -0.254104 -0.615315 -0.194236 -0.772257 -1.061067   \n",
       "1           72  0.017020  0.213820  0.027107  0.849834  0.482972  0.217779   \n",
       "2           48  0.462792  0.981712 -0.091777 -0.039121  1.055526  0.161005   \n",
       "3           48 -0.531916 -0.269127  0.455184  1.595325 -0.621171 -1.509230   \n",
       "4           72 -0.341668  0.808567  0.604615  0.951946 -0.630950 -0.243933   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "21943       72  0.089366  0.176202 -0.226762 -0.244678  0.396468 -0.094758   \n",
       "21944       24  0.072056 -0.131998 -0.499092 -0.479222  0.667644  0.530397   \n",
       "21945       24 -1.346695 -0.369847  0.878667 -0.735139  0.613056 -0.194656   \n",
       "21946       24  0.490027  0.329593  0.157679  0.732402  0.001062  0.034881   \n",
       "21947       72 -0.939748 -0.153659  0.695101 -0.365699 -1.352665 -1.150624   \n",
       "\n",
       "            g-7       g-8       g-9  ...    g_kurt    c_kurt   gc_kurt  \\\n",
       "0      0.005623  0.513989 -0.130963  ... -0.006219 -0.250230 -0.026184   \n",
       "1      0.363904 -0.298420  0.730029  ... -0.053247  0.111352 -0.099643   \n",
       "2      0.242395  0.050070  0.975415  ... -0.362998 -0.051865 -0.282383   \n",
       "3      0.206249 -0.066407 -0.889590  ... -0.880856  4.444686 -0.909214   \n",
       "4     -0.103294 -0.684346  0.741863  ... -0.351803 -0.477550 -0.240858   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "21943 -0.130161 -0.582338  0.056587  ... -0.031021 -0.228406 -0.011154   \n",
       "21944  0.333563 -0.356318  0.048109  ...  0.196997 -0.145076  0.253493   \n",
       "21945 -0.446960  0.479298  0.549999  ...  0.102816 -0.157828  0.107293   \n",
       "21946  0.079245  0.405150 -0.742506  ... -1.023389 -0.579405 -0.914582   \n",
       "21947  1.045868  1.472960  0.980444  ... -0.861486  5.260566 -0.945209   \n",
       "\n",
       "         g_skew    c_skew   gc_skew  cp_dose_time  cp_type_trt_cp  cp_dose_D1  \\\n",
       "0     -0.008259  0.118667 -0.036543             0               1           1   \n",
       "1      0.096482 -0.043717  0.003754             2               1           1   \n",
       "2     -0.017658  0.379548  0.010043             1               1           1   \n",
       "3      0.108938  2.010409  0.273694             1               1           1   \n",
       "4     -0.130955  0.191181 -0.201224             5               1           0   \n",
       "...         ...       ...       ...           ...             ...         ...   \n",
       "21943 -0.083142  0.473883 -0.017303             2               1           1   \n",
       "21944 -0.222104  0.367298 -0.168144             3               1           0   \n",
       "21945 -0.021382  0.484219  0.055402             3               1           0   \n",
       "21946 -0.140780  0.200423 -0.189765             0               1           1   \n",
       "21947  0.012017  1.850527  0.219300             2               1           1   \n",
       "\n",
       "       cp_dose_D2  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "21943           0  \n",
       "21944           1  \n",
       "21945           1  \n",
       "21946           0  \n",
       "21947           0  \n",
       "\n",
       "[21948 rows x 996 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b88ba9a1-8c8f-4017-8f66-11502b1a66c0",
    "_uuid": "ec5a0a57-9fe2-4010-b301-4eebe652da87",
    "papermill": {
     "duration": 0.054627,
     "end_time": "2020-11-05T22:45:35.194318",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.139691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2 Define Error/Loss Metric and Prediction clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "efaf4180-50af-4dcc-b3b0-1c4038301ce5",
    "_uuid": "16856a4e-8060-40d7-ac95-632d81b42b95",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:35.313520Z",
     "iopub.status.busy": "2020-11-05T22:45:35.312644Z",
     "iopub.status.idle": "2020-11-05T22:45:35.316992Z",
     "shell.execute_reply": "2020-11-05T22:45:35.316447Z"
    },
    "papermill": {
     "duration": 0.066889,
     "end_time": "2020-11-05T22:45:35.317107",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.250218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_log_loss(y_true, y_pred):\n",
    "    losses = []\n",
    "    for col in y_true.columns:\n",
    "        losses.append(log_loss(y_true.loc[:, col], y_pred.loc[:, col]))\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "516b17c4-4697-4194-a9a1-e07020699394",
    "_uuid": "ad337b21-38a2-4984-b182-05c23e91307b",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:35.433453Z",
     "iopub.status.busy": "2020-11-05T22:45:35.432589Z",
     "iopub.status.idle": "2020-11-05T22:45:35.435681Z",
     "shell.execute_reply": "2020-11-05T22:45:35.435062Z"
    },
    "papermill": {
     "duration": 0.062938,
     "end_time": "2020-11-05T22:45:35.435823",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.372885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip(y_pred, c_min, c_max):\n",
    "    return np.clip(y_pred, c_min, c_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "c1529cef-55df-4c59-a23d-2b21e6dd49ba",
    "_uuid": "6af491c3-aebc-4fd9-b2f8-1a78fe1c71a4",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:35.552498Z",
     "iopub.status.busy": "2020-11-05T22:45:35.551517Z",
     "iopub.status.idle": "2020-11-05T22:45:35.554827Z",
     "shell.execute_reply": "2020-11-05T22:45:35.554223Z"
    },
    "papermill": {
     "duration": 0.063585,
     "end_time": "2020-11-05T22:45:35.554933",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.491348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_min = 0.001\n",
    "p_max = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1d569890-835d-4698-b4d3-52ae6ee6adea",
    "_uuid": "af8f3cde-4a98-4edb-a255-6d845e38a274",
    "papermill": {
     "duration": 0.058141,
     "end_time": "2020-11-05T22:45:35.671466",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.613325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Create Model and Perform KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055827,
     "end_time": "2020-11-05T22:45:35.784681",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.728854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1 Two Layer DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:35.916768Z",
     "iopub.status.busy": "2020-11-05T22:45:35.915748Z",
     "iopub.status.idle": "2020-11-05T22:45:35.918357Z",
     "shell.execute_reply": "2020-11-05T22:45:35.918872Z"
    },
    "papermill": {
     "duration": 0.07376,
     "end_time": "2020-11-05T22:45:35.919009",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.845249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The model param is tuned with optuna \n",
    "#The leaky ReLu performs the best\n",
    "def create_model_v1(shape):\n",
    "    model = M.Sequential()\n",
    "    model.add(L.Input(shape = (shape)))\n",
    "    model.add(L.BatchNormalization())\n",
    "    model.add(L.Dropout(0.397816152960733))\n",
    "    model.add(tfa.layers.WeightNormalization(L.Dense(521)))\n",
    "    model.add(L.LeakyReLU(alpha = 0.10059420295821832))\n",
    "    model.add(L.BatchNormalization())\n",
    "    model.add(L.Dropout(0.4365714774136811))\n",
    "    model.add(tfa.layers.WeightNormalization(L.Dense(1634)))\n",
    "    model.add(L.LeakyReLU(alpha = 0.10059420295821832))\n",
    "    model.add(L.BatchNormalization())\n",
    "    model.add(L.Dropout(0.4365714774136811))\n",
    "    model.add(tfa.layers.WeightNormalization(L.Dense(206, activation = \"sigmoid\")))\n",
    "    model.compile(optimizer=tfa.optimizers.AdamW(lr = 1e-3, weight_decay = 1e-5, clipvalue = 756), \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0015),\n",
    "                  metrics=tf.keras.metrics.BinaryCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056477,
     "end_time": "2020-11-05T22:45:36.033722",
     "exception": false,
     "start_time": "2020-11-05T22:45:35.977245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2 TabNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056295,
     "end_time": "2020-11-05T22:45:36.146690",
     "exception": false,
     "start_time": "2020-11-05T22:45:36.090395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.2.1 AdaBelief Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:36.286285Z",
     "iopub.status.busy": "2020-11-05T22:45:36.270022Z",
     "iopub.status.idle": "2020-11-05T22:45:36.316994Z",
     "shell.execute_reply": "2020-11-05T22:45:36.316343Z"
    },
    "papermill": {
     "duration": 0.113861,
     "end_time": "2020-11-05T22:45:36.317113",
     "exception": false,
     "start_time": "2020-11-05T22:45:36.203252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "version_higher = ( torch.__version__ >= \"1.5.0\" )\n",
    "\n",
    "class AdaBelief(Optimizer):\n",
    "    r\"\"\"Implements AdaBelief algorithm. Modified from Adam in PyTorch\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-3)\n",
    "        betas (Tuple[float, float], optional): coefficients used for computing\n",
    "            running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
    "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
    "            (default: False)\n",
    "        weight_decouple (boolean, optional): ( default: False) If set as True, then\n",
    "            the optimizer uses decoupled weight decay as in AdamW\n",
    "        fixed_decay (boolean, optional): (default: False) This is used when weight_decouple\n",
    "            is set as True.\n",
    "            When fixed_decay == True, the weight decay is performed as\n",
    "            $W_{new} = W_{old} - W_{old} \\times decay$.\n",
    "            When fixed_decay == False, the weight decay is performed as\n",
    "            $W_{new} = W_{old} - W_{old} \\times decay \\times lr$. Note that in this case, the\n",
    "            weight decay ratio decreases with learning rate (lr).\n",
    "        rectify (boolean, optional): (default: False) If set as True, then perform the rectified\n",
    "            update similar to RAdam\n",
    "    reference: AdaBelief Optimizer, adapting stepsizes by the belief in observed gradients\n",
    "               NeurIPS 2020 Spotlight\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                 weight_decay=0, amsgrad=False, weight_decouple = False, fixed_decay=False, rectify = False ):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "        super(AdaBelief, self).__init__(params, defaults)\n",
    "\n",
    "        self.weight_decouple = weight_decouple\n",
    "        self.rectify = rectify\n",
    "        self.fixed_decay = fixed_decay\n",
    "        if self.weight_decouple:\n",
    "            print('Weight decoupling enabled in AdaBelief')\n",
    "            if self.fixed_decay:\n",
    "                print('Weight decay fixed')\n",
    "        if self.rectify:\n",
    "            print('Rectification enabled in AdaBelief')\n",
    "        if amsgrad:\n",
    "            print('AMS enabled in AdaBelief')\n",
    "    def __setstate__(self, state):\n",
    "        super(AdaBelief, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('amsgrad', False)\n",
    "\n",
    "    def reset(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                amsgrad = group['amsgrad']\n",
    "\n",
    "                # State initialization\n",
    "                state['step'] = 0\n",
    "                # Exponential moving average of gradient values\n",
    "                state['exp_avg'] = torch.zeros_like(p.data,\n",
    "                                   memory_format=torch.preserve_format) if version_higher else torch.zeros_like(p.data)\n",
    "\n",
    "                # Exponential moving average of squared gradient values\n",
    "                state['exp_avg_var'] = torch.zeros_like(p.data,\n",
    "                                    memory_format=torch.preserve_format) if version_higher else torch.zeros_like(p.data)\n",
    "                if amsgrad:\n",
    "                    # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                    state['max_exp_avg_var'] = torch.zeros_like(p.data,\n",
    "                                    memory_format=torch.preserve_format) if version_higher else torch.zeros_like(p.data)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('AdaBelief does not support sparse gradients, please consider SparseAdam instead')\n",
    "                amsgrad = group['amsgrad']\n",
    "\n",
    "                state = self.state[p]\n",
    "               \n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['rho_inf'] = 2.0 / (1.0 - beta2) - 1.0\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data,\n",
    "                                    memory_format=torch.preserve_format) if version_higher else torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_var'] = torch.zeros_like(p.data,\n",
    "                                    memory_format=torch.preserve_format) if version_higher else torch.zeros_like(p.data)\n",
    "                    if amsgrad:\n",
    "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                        state['max_exp_avg_var'] = torch.zeros_like(p.data,\n",
    "                                    memory_format=torch.preserve_format) if version_higher else torch.zeros_like(p.data)\n",
    "\n",
    "                # get current state variable\n",
    "                exp_avg, exp_avg_var = state['exp_avg'], state['exp_avg_var']\n",
    "\n",
    "                state['step'] += 1\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "\n",
    "                # perform weight decay, check if decoupled weight decay\n",
    "                if self.weight_decouple:\n",
    "                    if not self.fixed_decay:\n",
    "                        p.data.mul_(1.0 - group['lr'] * group['weight_decay'])\n",
    "                    else:\n",
    "                        p.data.mul_(1.0 - group['weight_decay'])\n",
    "                else:\n",
    "                    if group['weight_decay'] != 0:\n",
    "                        grad.add_(group['weight_decay'], p.data)\n",
    "\n",
    "                # Update first and second moment running average\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                grad_residual = grad - exp_avg\n",
    "                exp_avg_var.mul_(beta2).addcmul_(1 - beta2, grad_residual, grad_residual)\n",
    "\n",
    "                if amsgrad:\n",
    "                    max_exp_avg_var = state['max_exp_avg_var']\n",
    "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                    torch.max(max_exp_avg_var, exp_avg_var, out=max_exp_avg_var)\n",
    "\n",
    "                    # Use the max. for normalizing running avg. of gradient\n",
    "                    denom = (max_exp_avg_var.add_(group['eps']).sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
    "                else:\n",
    "                    denom = (exp_avg_var.add_(group['eps']).sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
    "\n",
    "                if not self.rectify:\n",
    "                    # Default update\n",
    "                    step_size = group['lr'] / bias_correction1\n",
    "                    p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                else:# Rectified update\n",
    "                    # calculate rho_t\n",
    "                    state['rho_t'] = state['rho_inf'] - 2 * state['step'] * beta2 ** state['step'] / (\n",
    "                            1.0 - beta2 ** state['step'])\n",
    "\n",
    "                    if state['rho_t'] > 4: # perform Adam style update if variance is small\n",
    "                        rho_inf, rho_t = state['rho_inf'], state['rho_t']\n",
    "                        rt = (rho_t - 4.0) * (rho_t - 2.0) * rho_inf / (rho_inf - 4.0) / (rho_inf - 2.0) / rho_t\n",
    "                        rt = math.sqrt(rt)\n",
    "\n",
    "                        step_size = rt * group['lr'] / bias_correction1\n",
    "\n",
    "                        p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                    else: # perform SGD style update\n",
    "                        p.data.add_( -group['lr'], exp_avg)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.094925,
     "end_time": "2020-11-05T22:45:36.468624",
     "exception": false,
     "start_time": "2020-11-05T22:45:36.373699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.2.2 Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:36.590406Z",
     "iopub.status.busy": "2020-11-05T22:45:36.589444Z",
     "iopub.status.idle": "2020-11-05T22:45:36.592635Z",
     "shell.execute_reply": "2020-11-05T22:45:36.592148Z"
    },
    "papermill": {
     "duration": 0.067197,
     "end_time": "2020-11-05T22:45:36.592763",
     "exception": false,
     "start_time": "2020-11-05T22:45:36.525566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 200\n",
    "tabnet_params = dict(\n",
    "    n_d = 28,\n",
    "    n_a = 28,\n",
    "    n_steps = 1,\n",
    "    gamma = 1.3,\n",
    "    lambda_sparse = 0,\n",
    "    optimizer_fn = AdaBelief,\n",
    "    optimizer_params = dict(lr = 7e-3, weight_decay = 1e-5, eps=1e-15),\n",
    "    mask_type = \"entmax\",\n",
    "    scheduler_params = dict(\n",
    "        mode = \"min\", patience = 5, min_lr = 7e-6, factor = 0.4),\n",
    "    scheduler_fn = ReduceLROnPlateau,\n",
    "    seed = 1,\n",
    "    verbose = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058601,
     "end_time": "2020-11-05T22:45:36.708680",
     "exception": false,
     "start_time": "2020-11-05T22:45:36.650079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.2.3 Custom Metric for TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:36.838360Z",
     "iopub.status.busy": "2020-11-05T22:45:36.837117Z",
     "iopub.status.idle": "2020-11-05T22:45:36.850943Z",
     "shell.execute_reply": "2020-11-05T22:45:36.851667Z"
    },
    "papermill": {
     "duration": 0.085139,
     "end_time": "2020-11-05T22:45:36.851905",
     "exception": false,
     "start_time": "2020-11-05T22:45:36.766766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    \"\"\"\n",
    "    LogLoss with sigmoid applied\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute LogLoss of predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: np.ndarray\n",
    "            Target matrix or vector\n",
    "        y_score: np.ndarray\n",
    "            Score matrix or vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "            LogLoss of predictions vs targets.\n",
    "        \"\"\"\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.091831,
     "end_time": "2020-11-05T22:45:37.039480",
     "exception": false,
     "start_time": "2020-11-05T22:45:36.947649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3 KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "244e8f03-2225-496c-8215-c4487bfd8e61",
    "_uuid": "65dcb7f8-edf5-4544-a311-fa8202b8c793",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:37.218370Z",
     "iopub.status.busy": "2020-11-05T22:45:37.217302Z",
     "iopub.status.idle": "2020-11-05T22:45:37.245098Z",
     "shell.execute_reply": "2020-11-05T22:45:37.246295Z"
    },
    "papermill": {
     "duration": 0.122457,
     "end_time": "2020-11-05T22:45:37.246494",
     "exception": false,
     "start_time": "2020-11-05T22:45:37.124037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_folds(folds):\n",
    "    models = []\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        seed = i\n",
    "        seed_everything(seed)\n",
    "        \n",
    "        model_list = list()\n",
    "        kfold = MultilabelStratifiedKFold(folds, shuffle = True, random_state = seed)\n",
    "        oof_preds = train_targets.copy()\n",
    "        \n",
    "        print(f\"REAPEAT NUMBER {i + 1} SEED {seed}\")\n",
    "        print(\"TabNet\")\n",
    "        \n",
    "        for fold, (train_ind, val_ind) in enumerate(kfold.split(train_targets, train_targets)):\n",
    "            \n",
    "            if fold % 2 == 0:\n",
    "                model = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "                print('\\n')\n",
    "                print('-'*50)\n",
    "                print(f'Training fold {fold + 1}')\n",
    "                \n",
    "                \n",
    "                model.fit(X_train = train_features.values[train_ind], y_train = train_targets.values[train_ind], eval_set = [(train_features.values[val_ind], train_targets.values[val_ind])], \n",
    "                          eval_name = [\"val\"], eval_metric = [\"logits_ll\"], max_epochs = MAX_EPOCH,\n",
    "                        patience = 20, batch_size = 256, virtual_batch_size = 32, num_workers = 2, drop_last = False,\n",
    "                        # To use binary cross entropy because this is not a regression problem\n",
    "                        loss_fn = F.binary_cross_entropy_with_logits\n",
    "                        )\n",
    "                model_list.append(model)\n",
    "                preds = model.predict(train_features.values[val_ind])\n",
    "                preds = 1 / (1 + np.exp(-preds))\n",
    "                oof_preds.loc[val_ind, :] = clip(preds, p_min, p_max)\n",
    "            \n",
    "            else:\n",
    "                model = create_model_v1(996)\n",
    "            \n",
    "                print('\\n')\n",
    "                print('-'*50)\n",
    "                print(f'Training fold {fold + 1}')\n",
    "\n",
    "                checkpoint_path = f'repeat:{seed}_Fold:{fold}.hdf5'\n",
    "                cb_checkpt = C.ModelCheckpoint(checkpoint_path, monitor = 'val_binary_crossentropy', verbose = 2, save_best_only = True, save_weights_only = True, mode = 'auto')\n",
    "                reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_binary_crossentropy',\n",
    "                                                             mode = 'min',\n",
    "                                                             factor = 0.2,\n",
    "                                                             patience = 3,\n",
    "                                                             verbose = 3)\n",
    "                early = tf.keras.callbacks.EarlyStopping(monitor = 'val_binary_crossentropy',\n",
    "                                                              mode = 'min',\n",
    "                                                              patience = 10,\n",
    "                                                              restore_best_weights = True,\n",
    "                                                              verbose = 3)\n",
    "                model.fit(train_features.values[train_ind],\n",
    "                    train_targets.values[train_ind], validation_data=(train_features.values[val_ind], train_targets.values[val_ind]),\n",
    "                        epochs=100, batch_size=128, verbose=2, callbacks = [reduce_lr, early, cb_checkpt])\n",
    "                model_list.append(model)\n",
    "                model.load_weights(checkpoint_path)\n",
    "                oof_preds.loc[val_ind, :] = clip(model.predict(train_features.values[val_ind]), p_min, p_max)\n",
    "\n",
    "        m, oof = model_list, oof_preds\n",
    "        models = models + m\n",
    "        \n",
    "        predictions.append(oof)\n",
    "    return models, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "29fa0f27-87b8-4fce-bc79-f669825381fa",
    "_uuid": "237db3f7-035b-4c21-87a1-1dbc90f6176a",
    "execution": {
     "iopub.execute_input": "2020-11-05T22:45:37.435715Z",
     "iopub.status.busy": "2020-11-05T22:45:37.428152Z",
     "iopub.status.idle": "2020-11-05T23:57:42.264767Z",
     "shell.execute_reply": "2020-11-05T23:57:42.265383Z"
    },
    "papermill": {
     "duration": 4324.930536,
     "end_time": "2020-11-05T23:57:42.265597",
     "exception": false,
     "start_time": "2020-11-05T22:45:37.335061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAPEAT NUMBER 1 SEED 0\n",
      "TabNet\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:135: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.1785  | val_logits_ll: 0.02261 |  0:00:03s\n",
      "epoch 10 | loss: 0.01798 | val_logits_ll: 0.01775 |  0:00:32s\n",
      "epoch 20 | loss: 0.0171  | val_logits_ll: 0.01709 |  0:01:03s\n",
      "epoch 30 | loss: 0.01684 | val_logits_ll: 0.01722 |  0:01:33s\n",
      "epoch 40 | loss: 0.01581 | val_logits_ll: 0.01669 |  0:02:04s\n",
      "epoch 50 | loss: 0.01415 | val_logits_ll: 0.01685 |  0:02:32s\n",
      "epoch 60 | loss: 0.01323 | val_logits_ll: 0.01739 |  0:03:03s\n",
      "\n",
      "Early stopping occured at epoch 62 with best_epoch = 42 and best_val_logits_ll = 0.0165\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04444, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 2s - loss: 0.3495 - binary_crossentropy: 0.3484 - val_loss: 0.0471 - val_binary_crossentropy: 0.0444\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04444 to 0.02263, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0342 - binary_crossentropy: 0.0309 - val_loss: 0.0263 - val_binary_crossentropy: 0.0226\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02263 to 0.02008, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0265 - binary_crossentropy: 0.0226 - val_loss: 0.0242 - val_binary_crossentropy: 0.0201\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02008 to 0.01889, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0247 - binary_crossentropy: 0.0205 - val_loss: 0.0232 - val_binary_crossentropy: 0.0189\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01889 to 0.01825, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0227 - val_binary_crossentropy: 0.0182\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01825 to 0.01785, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0223 - val_binary_crossentropy: 0.0178\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01785 to 0.01757, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0183 - val_loss: 0.0221 - val_binary_crossentropy: 0.0176\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01757 to 0.01730, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0180 - val_loss: 0.0219 - val_binary_crossentropy: 0.0173\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01730 to 0.01710, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0223 - binary_crossentropy: 0.0176 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01710 to 0.01689, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0221 - binary_crossentropy: 0.0174 - val_loss: 0.0216 - val_binary_crossentropy: 0.0169\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01689 to 0.01681, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0218 - binary_crossentropy: 0.0171 - val_loss: 0.0215 - val_binary_crossentropy: 0.0168\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01681 to 0.01668, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0168 - val_loss: 0.0214 - val_binary_crossentropy: 0.0167\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01668 to 0.01662, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01662 to 0.01640, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0165 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01640 to 0.01639, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0162 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01639 to 0.01637, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01637 to 0.01620, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01620 to 0.01618, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0205 - binary_crossentropy: 0.0155 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01618 to 0.01608, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 2s - loss: 0.0202 - binary_crossentropy: 0.0153 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy did not improve from 0.01608\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01608 to 0.01604, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy did not improve from 0.01604\n",
      "155/155 - 2s - loss: 0.0198 - binary_crossentropy: 0.0147 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01604 to 0.01596, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01596 to 0.01593, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0140 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01593 to 0.01589, saving model to repeat:0_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0139 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0137 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0137 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 36/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01589\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 00036: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 3\n",
      "epoch 0  | loss: 0.17792 | val_logits_ll: 0.02256 |  0:00:02s\n",
      "epoch 10 | loss: 0.01799 | val_logits_ll: 0.01799 |  0:00:33s\n",
      "epoch 20 | loss: 0.01717 | val_logits_ll: 0.01756 |  0:01:04s\n",
      "epoch 30 | loss: 0.01608 | val_logits_ll: 0.01694 |  0:01:35s\n",
      "epoch 40 | loss: 0.0155  | val_logits_ll: 0.01687 |  0:02:07s\n",
      "epoch 50 | loss: 0.01347 | val_logits_ll: 0.01722 |  0:02:38s\n",
      "epoch 60 | loss: 0.01241 | val_logits_ll: 0.01789 |  0:03:08s\n",
      "\n",
      "Early stopping occured at epoch 62 with best_epoch = 42 and best_val_logits_ll = 0.01668\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04157, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.3511 - binary_crossentropy: 0.3500 - val_loss: 0.0442 - val_binary_crossentropy: 0.0416\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04157 to 0.02276, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0341 - binary_crossentropy: 0.0309 - val_loss: 0.0264 - val_binary_crossentropy: 0.0228\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02276 to 0.02005, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0264 - binary_crossentropy: 0.0225 - val_loss: 0.0241 - val_binary_crossentropy: 0.0201\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02005 to 0.01903, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0247 - binary_crossentropy: 0.0204 - val_loss: 0.0233 - val_binary_crossentropy: 0.0190\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01903 to 0.01844, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0229 - val_binary_crossentropy: 0.0184\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01844 to 0.01800, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0225 - val_binary_crossentropy: 0.0180\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01800 to 0.01768, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0184 - val_loss: 0.0222 - val_binary_crossentropy: 0.0177\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01768 to 0.01750, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0180 - val_loss: 0.0221 - val_binary_crossentropy: 0.0175\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01750 to 0.01747, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0224 - binary_crossentropy: 0.0177 - val_loss: 0.0220 - val_binary_crossentropy: 0.0175\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01747 to 0.01719, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0221 - binary_crossentropy: 0.0174 - val_loss: 0.0219 - val_binary_crossentropy: 0.0172\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01719 to 0.01715, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.0221 - binary_crossentropy: 0.0174 - val_loss: 0.0220 - val_binary_crossentropy: 0.0172\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01715 to 0.01696, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0171 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01696 to 0.01691, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0215 - binary_crossentropy: 0.0167 - val_loss: 0.0216 - val_binary_crossentropy: 0.0169\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01691 to 0.01660, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0165 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01660 to 0.01658, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.0211 - binary_crossentropy: 0.0162 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01658 to 0.01645, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01645 to 0.01643, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0207 - binary_crossentropy: 0.0158 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01643 to 0.01628, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0205 - binary_crossentropy: 0.0156 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01628 to 0.01628, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.0203 - binary_crossentropy: 0.0154 - val_loss: 0.0211 - val_binary_crossentropy: 0.0163\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01628 to 0.01620, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy did not improve from 0.01620\n",
      "155/155 - 1s - loss: 0.0203 - binary_crossentropy: 0.0153 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01620 to 0.01608, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0195 - binary_crossentropy: 0.0145 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01608 to 0.01605, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0195 - binary_crossentropy: 0.0145 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01605 to 0.01603, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01603 to 0.01602, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0143 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01602 to 0.01601, saving model to repeat:0_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 36/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01601\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 00036: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 5\n",
      "epoch 0  | loss: 0.17722 | val_logits_ll: 0.02255 |  0:00:03s\n",
      "epoch 10 | loss: 0.01798 | val_logits_ll: 0.01812 |  0:00:34s\n",
      "epoch 20 | loss: 0.01716 | val_logits_ll: 0.01754 |  0:01:05s\n",
      "epoch 30 | loss: 0.01684 | val_logits_ll: 0.01736 |  0:01:37s\n",
      "epoch 40 | loss: 0.01662 | val_logits_ll: 0.017   |  0:02:08s\n",
      "epoch 50 | loss: 0.01642 | val_logits_ll: 0.01697 |  0:02:40s\n",
      "epoch 60 | loss: 0.01538 | val_logits_ll: 0.01678 |  0:03:11s\n",
      "epoch 70 | loss: 0.0139  | val_logits_ll: 0.01675 |  0:03:42s\n",
      "\n",
      "Early stopping occured at epoch 76 with best_epoch = 56 and best_val_logits_ll = 0.01644\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04154, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 2s - loss: 0.3543 - binary_crossentropy: 0.3532 - val_loss: 0.0443 - val_binary_crossentropy: 0.0415\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04154 to 0.02237, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0341 - binary_crossentropy: 0.0309 - val_loss: 0.0261 - val_binary_crossentropy: 0.0224\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02237 to 0.02132, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0264 - binary_crossentropy: 0.0226 - val_loss: 0.0253 - val_binary_crossentropy: 0.0213\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02132 to 0.01914, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0250 - binary_crossentropy: 0.0208 - val_loss: 0.0234 - val_binary_crossentropy: 0.0191\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01914 to 0.01845, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0228 - val_binary_crossentropy: 0.0184\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01845 to 0.01796, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0225 - val_binary_crossentropy: 0.0180\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01796 to 0.01764, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 2s - loss: 0.0229 - binary_crossentropy: 0.0184 - val_loss: 0.0222 - val_binary_crossentropy: 0.0176\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01764 to 0.01733, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0180 - val_loss: 0.0220 - val_binary_crossentropy: 0.0173\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01733 to 0.01728, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0224 - binary_crossentropy: 0.0178 - val_loss: 0.0219 - val_binary_crossentropy: 0.0173\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01728 to 0.01696, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0221 - binary_crossentropy: 0.0174 - val_loss: 0.0216 - val_binary_crossentropy: 0.0170\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01696 to 0.01682, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0172 - val_loss: 0.0215 - val_binary_crossentropy: 0.0168\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01682 to 0.01667, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0217 - binary_crossentropy: 0.0169 - val_loss: 0.0214 - val_binary_crossentropy: 0.0167\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01667 to 0.01659, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0213 - val_binary_crossentropy: 0.0166\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01659 to 0.01643, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0164 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01643 to 0.01634, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0162 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01634 to 0.01627, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0211 - val_binary_crossentropy: 0.0163\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01627 to 0.01624, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01624 to 0.01619, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 2s - loss: 0.0207 - binary_crossentropy: 0.0158 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01619 to 0.01607, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0203 - binary_crossentropy: 0.0154 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01607 to 0.01603, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0201 - binary_crossentropy: 0.0152 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01603 to 0.01600, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01600 to 0.01597, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0148 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01597 to 0.01584, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0143 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy did not improve from 0.01584\n",
      "155/155 - 1s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01584 to 0.01582, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01582 to 0.01580, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01580 to 0.01580, saving model to repeat:0_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0137 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 37/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01580\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0139 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 00037: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 7\n",
      "epoch 0  | loss: 0.17832 | val_logits_ll: 0.02261 |  0:00:02s\n",
      "epoch 10 | loss: 0.01814 | val_logits_ll: 0.01801 |  0:00:34s\n",
      "epoch 20 | loss: 0.01733 | val_logits_ll: 0.01785 |  0:01:06s\n",
      "epoch 30 | loss: 0.01695 | val_logits_ll: 0.0171  |  0:01:38s\n",
      "epoch 40 | loss: 0.01623 | val_logits_ll: 0.0165  |  0:02:10s\n",
      "epoch 50 | loss: 0.01557 | val_logits_ll: 0.01645 |  0:02:42s\n",
      "epoch 60 | loss: 0.01443 | val_logits_ll: 0.01638 |  0:03:13s\n",
      "epoch 70 | loss: 0.01322 | val_logits_ll: 0.01706 |  0:03:46s\n",
      "\n",
      "Early stopping occured at epoch 79 with best_epoch = 59 and best_val_logits_ll = 0.01634\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 8\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.03981, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.3514 - binary_crossentropy: 0.3503 - val_loss: 0.0425 - val_binary_crossentropy: 0.0398\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.03981 to 0.02274, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0343 - binary_crossentropy: 0.0311 - val_loss: 0.0265 - val_binary_crossentropy: 0.0227\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02274 to 0.02036, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0264 - binary_crossentropy: 0.0225 - val_loss: 0.0244 - val_binary_crossentropy: 0.0204\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02036 to 0.01939, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0248 - binary_crossentropy: 0.0206 - val_loss: 0.0237 - val_binary_crossentropy: 0.0194\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01939 to 0.01856, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0230 - val_binary_crossentropy: 0.0186\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.01856\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0234 - val_binary_crossentropy: 0.0190\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01856 to 0.01776, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0230 - binary_crossentropy: 0.0184 - val_loss: 0.0223 - val_binary_crossentropy: 0.0178\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01776 to 0.01734, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0179 - val_loss: 0.0220 - val_binary_crossentropy: 0.0173\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01734 to 0.01725, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0222 - binary_crossentropy: 0.0176 - val_loss: 0.0219 - val_binary_crossentropy: 0.0172\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01725 to 0.01709, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0220 - binary_crossentropy: 0.0173 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01709 to 0.01696, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0218 - binary_crossentropy: 0.0171 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.01696\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0169 - val_loss: 0.0218 - val_binary_crossentropy: 0.0170\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01696 to 0.01665, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0215 - val_binary_crossentropy: 0.0167\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01665 to 0.01655, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0212 - binary_crossentropy: 0.0163 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01655 to 0.01652, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0209 - binary_crossentropy: 0.0161 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01652 to 0.01634, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0207 - binary_crossentropy: 0.0159 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01634 to 0.01633, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01633 to 0.01627, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0154 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01627 to 0.01619, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01619 to 0.01614, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0148 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01614 to 0.01595, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0197 - binary_crossentropy: 0.0146 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy did not improve from 0.01595\n",
      "155/155 - 1s - loss: 0.0195 - binary_crossentropy: 0.0144 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy did not improve from 0.01595\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0143 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy did not improve from 0.01595\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0142 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01595 to 0.01587, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0136 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01587 to 0.01583, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0134 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0184 - binary_crossentropy: 0.0133 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0131 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0130 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy improved from 0.01583 to 0.01582, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0130 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy improved from 0.01582 to 0.01582, saving model to repeat:0_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00039: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0130 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0130 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0131 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00042: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0131 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 43/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00043: val_binary_crossentropy did not improve from 0.01582\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0131 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 00043: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 9\n",
      "epoch 0  | loss: 0.17966 | val_logits_ll: 0.02236 |  0:00:03s\n",
      "epoch 10 | loss: 0.01854 | val_logits_ll: 0.01843 |  0:00:35s\n",
      "epoch 20 | loss: 0.01732 | val_logits_ll: 0.01766 |  0:01:06s\n",
      "epoch 30 | loss: 0.01624 | val_logits_ll: 0.01694 |  0:01:38s\n",
      "epoch 40 | loss: 0.01475 | val_logits_ll: 0.01695 |  0:02:09s\n",
      "epoch 50 | loss: 0.01372 | val_logits_ll: 0.01742 |  0:02:42s\n",
      "\n",
      "Early stopping occured at epoch 53 with best_epoch = 33 and best_val_logits_ll = 0.01674\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 10\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04140, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.3523 - binary_crossentropy: 0.3512 - val_loss: 0.0441 - val_binary_crossentropy: 0.0414\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04140 to 0.02294, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0345 - binary_crossentropy: 0.0313 - val_loss: 0.0266 - val_binary_crossentropy: 0.0229\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02294 to 0.02042, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0264 - binary_crossentropy: 0.0225 - val_loss: 0.0245 - val_binary_crossentropy: 0.0204\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02042 to 0.01923, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0246 - binary_crossentropy: 0.0204 - val_loss: 0.0235 - val_binary_crossentropy: 0.0192\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01923 to 0.01851, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0238 - binary_crossentropy: 0.0194 - val_loss: 0.0229 - val_binary_crossentropy: 0.0185\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01851 to 0.01806, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0226 - val_binary_crossentropy: 0.0181\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01806 to 0.01786, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0184 - val_loss: 0.0224 - val_binary_crossentropy: 0.0179\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01786 to 0.01746, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0227 - binary_crossentropy: 0.0180 - val_loss: 0.0221 - val_binary_crossentropy: 0.0175\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01746 to 0.01727, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0224 - binary_crossentropy: 0.0177 - val_loss: 0.0220 - val_binary_crossentropy: 0.0173\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01727 to 0.01714, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0222 - binary_crossentropy: 0.0174 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01714 to 0.01695, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0171 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01695 to 0.01690, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0169 - val_loss: 0.0217 - val_binary_crossentropy: 0.0169\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01690 to 0.01681, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0215 - binary_crossentropy: 0.0167 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01681 to 0.01662, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0212 - binary_crossentropy: 0.0164 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01662 to 0.01654, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0162 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01654 to 0.01641, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0160 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01641 to 0.01631, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy did not improve from 0.01631\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0155 - val_loss: 0.0213 - val_binary_crossentropy: 0.0163\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy did not improve from 0.01631\n",
      "155/155 - 1s - loss: 0.0203 - binary_crossentropy: 0.0154 - val_loss: 0.0213 - val_binary_crossentropy: 0.0163\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01631 to 0.01619, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0149 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01619 to 0.01614, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0197 - binary_crossentropy: 0.0147 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01614 to 0.01614, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.0196 - binary_crossentropy: 0.0146 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01614 to 0.01609, saving model to repeat:0_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0195 - binary_crossentropy: 0.0146 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0143 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 33/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01609\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0145 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 00033: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=1 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAPEAT NUMBER 2 SEED 1\n",
      "TabNet\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 1\n",
      "epoch 0  | loss: 0.17945 | val_logits_ll: 0.02286 |  0:00:03s\n",
      "epoch 10 | loss: 0.01853 | val_logits_ll: 0.01831 |  0:00:35s\n",
      "epoch 20 | loss: 0.01724 | val_logits_ll: 0.01727 |  0:01:09s\n",
      "epoch 30 | loss: 0.01694 | val_logits_ll: 0.01703 |  0:01:42s\n",
      "epoch 40 | loss: 0.01668 | val_logits_ll: 0.01674 |  0:02:15s\n",
      "epoch 50 | loss: 0.01562 | val_logits_ll: 0.01642 |  0:02:50s\n",
      "epoch 60 | loss: 0.01416 | val_logits_ll: 0.01662 |  0:03:23s\n",
      "\n",
      "Early stopping occured at epoch 67 with best_epoch = 47 and best_val_logits_ll = 0.01642\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.03970, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 2s - loss: 0.3519 - binary_crossentropy: 0.3508 - val_loss: 0.0424 - val_binary_crossentropy: 0.0397\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.03970 to 0.02287, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0345 - binary_crossentropy: 0.0313 - val_loss: 0.0266 - val_binary_crossentropy: 0.0229\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02287 to 0.02000, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0266 - binary_crossentropy: 0.0227 - val_loss: 0.0241 - val_binary_crossentropy: 0.0200\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02000 to 0.01894, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0246 - binary_crossentropy: 0.0204 - val_loss: 0.0233 - val_binary_crossentropy: 0.0189\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01894 to 0.01848, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0238 - binary_crossentropy: 0.0195 - val_loss: 0.0229 - val_binary_crossentropy: 0.0185\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01848 to 0.01798, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0225 - val_binary_crossentropy: 0.0180\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01798 to 0.01755, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0183 - val_loss: 0.0221 - val_binary_crossentropy: 0.0175\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01755 to 0.01732, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0180 - val_loss: 0.0219 - val_binary_crossentropy: 0.0173\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01732 to 0.01713, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0223 - binary_crossentropy: 0.0176 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01713 to 0.01695, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0222 - binary_crossentropy: 0.0174 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01695 to 0.01691, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0218 - binary_crossentropy: 0.0171 - val_loss: 0.0216 - val_binary_crossentropy: 0.0169\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01691 to 0.01678, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0217 - binary_crossentropy: 0.0169 - val_loss: 0.0215 - val_binary_crossentropy: 0.0168\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01678 to 0.01661, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0215 - binary_crossentropy: 0.0167 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01661 to 0.01657, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0165 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01657 to 0.01639, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0211 - binary_crossentropy: 0.0162 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy did not improve from 0.01639\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01639 to 0.01619, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy did not improve from 0.01619\n",
      "155/155 - 1s - loss: 0.0205 - binary_crossentropy: 0.0155 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01619 to 0.01611, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0203 - binary_crossentropy: 0.0154 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0201 - binary_crossentropy: 0.0151 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01611 to 0.01599, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0196 - binary_crossentropy: 0.0146 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01599 to 0.01598, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0195 - binary_crossentropy: 0.0145 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01598 to 0.01596, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01596 to 0.01591, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0143 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 2s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01591 to 0.01591, saving model to repeat:1_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0143 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0143 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0143 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 37/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01591\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0143 - val_loss: 0.0208 - val_binary_crossentropy: 0.0161\n",
      "Epoch 00037: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 3\n",
      "epoch 0  | loss: 0.17861 | val_logits_ll: 0.0226  |  0:00:02s\n",
      "epoch 10 | loss: 0.01826 | val_logits_ll: 0.01802 |  0:00:35s\n",
      "epoch 20 | loss: 0.01734 | val_logits_ll: 0.01769 |  0:01:07s\n",
      "epoch 30 | loss: 0.01688 | val_logits_ll: 0.01721 |  0:01:39s\n",
      "epoch 40 | loss: 0.01667 | val_logits_ll: 0.01713 |  0:02:11s\n",
      "epoch 50 | loss: 0.01657 | val_logits_ll: 0.01701 |  0:02:43s\n",
      "epoch 60 | loss: 0.01491 | val_logits_ll: 0.01664 |  0:03:15s\n",
      "epoch 70 | loss: 0.01377 | val_logits_ll: 0.01716 |  0:03:47s\n",
      "\n",
      "Early stopping occured at epoch 79 with best_epoch = 59 and best_val_logits_ll = 0.01662\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.03857, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.3502 - binary_crossentropy: 0.3491 - val_loss: 0.0413 - val_binary_crossentropy: 0.0386\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.03857 to 0.02293, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0345 - binary_crossentropy: 0.0313 - val_loss: 0.0267 - val_binary_crossentropy: 0.0229\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02293 to 0.02013, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0263 - binary_crossentropy: 0.0224 - val_loss: 0.0242 - val_binary_crossentropy: 0.0201\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02013 to 0.01911, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0246 - binary_crossentropy: 0.0204 - val_loss: 0.0234 - val_binary_crossentropy: 0.0191\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01911 to 0.01846, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0237 - binary_crossentropy: 0.0194 - val_loss: 0.0229 - val_binary_crossentropy: 0.0185\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01846 to 0.01820, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0227 - val_binary_crossentropy: 0.0182\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01820 to 0.01781, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0184 - val_loss: 0.0224 - val_binary_crossentropy: 0.0178\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01781 to 0.01762, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0225 - binary_crossentropy: 0.0179 - val_loss: 0.0222 - val_binary_crossentropy: 0.0176\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01762 to 0.01742, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0224 - binary_crossentropy: 0.0178 - val_loss: 0.0221 - val_binary_crossentropy: 0.0174\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01742 to 0.01726, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0220 - binary_crossentropy: 0.0173 - val_loss: 0.0219 - val_binary_crossentropy: 0.0173\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01726 to 0.01709, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.0218 - binary_crossentropy: 0.0171 - val_loss: 0.0219 - val_binary_crossentropy: 0.0171\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01709 to 0.01698, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0217 - binary_crossentropy: 0.0169 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01698 to 0.01695, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0170 - val_loss: 0.0218 - val_binary_crossentropy: 0.0169\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01695 to 0.01677, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0165 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01677 to 0.01665, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0211 - binary_crossentropy: 0.0162 - val_loss: 0.0215 - val_binary_crossentropy: 0.0166\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01665 to 0.01655, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0209 - binary_crossentropy: 0.0160 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy did not improve from 0.01655\n",
      "155/155 - 1s - loss: 0.0207 - binary_crossentropy: 0.0158 - val_loss: 0.0217 - val_binary_crossentropy: 0.0168\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01655 to 0.01640, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0156 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy did not improve from 0.01640\n",
      "155/155 - 1s - loss: 0.0203 - binary_crossentropy: 0.0154 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01640 to 0.01638, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01638 to 0.01635, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0213 - val_binary_crossentropy: 0.0163\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01635 to 0.01617, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0196 - binary_crossentropy: 0.0145 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy did not improve from 0.01617\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01617 to 0.01614, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0143 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01614 to 0.01611, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01611 to 0.01611, saving model to repeat:1_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0140 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0140 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 2s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0142 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 00037: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 5\n",
      "epoch 0  | loss: 0.1782  | val_logits_ll: 0.02268 |  0:00:03s\n",
      "epoch 10 | loss: 0.01804 | val_logits_ll: 0.0179  |  0:00:34s\n",
      "epoch 20 | loss: 0.01721 | val_logits_ll: 0.0173  |  0:01:06s\n",
      "epoch 30 | loss: 0.01697 | val_logits_ll: 0.01692 |  0:01:37s\n",
      "epoch 40 | loss: 0.01621 | val_logits_ll: 0.01647 |  0:02:09s\n",
      "epoch 50 | loss: 0.01541 | val_logits_ll: 0.01649 |  0:02:40s\n",
      "epoch 60 | loss: 0.01382 | val_logits_ll: 0.01678 |  0:03:12s\n",
      "\n",
      "Early stopping occured at epoch 66 with best_epoch = 46 and best_val_logits_ll = 0.01636\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.03994, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 2s - loss: 0.3505 - binary_crossentropy: 0.3494 - val_loss: 0.0427 - val_binary_crossentropy: 0.0399\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.03994 to 0.02284, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0340 - binary_crossentropy: 0.0307 - val_loss: 0.0265 - val_binary_crossentropy: 0.0228\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02284 to 0.02007, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0264 - binary_crossentropy: 0.0225 - val_loss: 0.0241 - val_binary_crossentropy: 0.0201\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02007 to 0.01896, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0248 - binary_crossentropy: 0.0206 - val_loss: 0.0233 - val_binary_crossentropy: 0.0190\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01896 to 0.01829, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0228 - val_binary_crossentropy: 0.0183\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01829 to 0.01789, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 2s - loss: 0.0232 - binary_crossentropy: 0.0187 - val_loss: 0.0224 - val_binary_crossentropy: 0.0179\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01789 to 0.01757, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0230 - binary_crossentropy: 0.0184 - val_loss: 0.0222 - val_binary_crossentropy: 0.0176\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01757 to 0.01747, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0180 - val_loss: 0.0220 - val_binary_crossentropy: 0.0175\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01747 to 0.01717, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0224 - binary_crossentropy: 0.0177 - val_loss: 0.0219 - val_binary_crossentropy: 0.0172\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01717 to 0.01701, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0221 - binary_crossentropy: 0.0174 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01701 to 0.01684, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0171 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01684 to 0.01674, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0168 - val_loss: 0.0215 - val_binary_crossentropy: 0.0167\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01674 to 0.01662, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01662 to 0.01652, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0165 - val_loss: 0.0213 - val_binary_crossentropy: 0.0165\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy did not improve from 0.01652\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0164 - val_loss: 0.0218 - val_binary_crossentropy: 0.0168\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01652 to 0.01640, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0161 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01640 to 0.01636, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0207 - binary_crossentropy: 0.0158 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01636 to 0.01626, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0155 - val_loss: 0.0211 - val_binary_crossentropy: 0.0163\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01626 to 0.01619, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0154 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01619 to 0.01614, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01614 to 0.01612, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01612 to 0.01604, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0148 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy did not improve from 0.01604\n",
      "155/155 - 1s - loss: 0.0197 - binary_crossentropy: 0.0146 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01604 to 0.01603, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0195 - binary_crossentropy: 0.0144 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01603 to 0.01597, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0143 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01597 to 0.01589, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01589 to 0.01586, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0136 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy improved from 0.01586 to 0.01585, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0135 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0184 - binary_crossentropy: 0.0133 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy improved from 0.01585 to 0.01585, saving model to repeat:1_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 2s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0182 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0182 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00038: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0132 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0133 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 40/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00040: val_binary_crossentropy did not improve from 0.01585\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0133 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 00040: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 7\n",
      "epoch 0  | loss: 0.17877 | val_logits_ll: 0.02256 |  0:00:02s\n",
      "epoch 10 | loss: 0.0181  | val_logits_ll: 0.01756 |  0:00:33s\n",
      "epoch 20 | loss: 0.01721 | val_logits_ll: 0.01711 |  0:01:05s\n",
      "epoch 30 | loss: 0.01687 | val_logits_ll: 0.01681 |  0:01:37s\n",
      "epoch 40 | loss: 0.01613 | val_logits_ll: 0.0164  |  0:02:08s\n",
      "epoch 50 | loss: 0.01474 | val_logits_ll: 0.0164  |  0:02:40s\n",
      "epoch 60 | loss: 0.01346 | val_logits_ll: 0.01681 |  0:03:11s\n",
      "\n",
      "Early stopping occured at epoch 68 with best_epoch = 48 and best_val_logits_ll = 0.01625\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 8\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04183, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.3521 - binary_crossentropy: 0.3510 - val_loss: 0.0445 - val_binary_crossentropy: 0.0418\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04183 to 0.02304, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0343 - binary_crossentropy: 0.0311 - val_loss: 0.0267 - val_binary_crossentropy: 0.0230\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02304 to 0.02009, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0263 - binary_crossentropy: 0.0224 - val_loss: 0.0241 - val_binary_crossentropy: 0.0201\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02009 to 0.01900, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0246 - binary_crossentropy: 0.0204 - val_loss: 0.0233 - val_binary_crossentropy: 0.0190\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy did not improve from 0.01900\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0196 - val_loss: 0.0237 - val_binary_crossentropy: 0.0194\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01900 to 0.01823, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0235 - binary_crossentropy: 0.0190 - val_loss: 0.0227 - val_binary_crossentropy: 0.0182\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01823 to 0.01782, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0183 - val_loss: 0.0224 - val_binary_crossentropy: 0.0178\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01782 to 0.01756, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0180 - val_loss: 0.0222 - val_binary_crossentropy: 0.0176\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01756 to 0.01744, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0223 - binary_crossentropy: 0.0176 - val_loss: 0.0220 - val_binary_crossentropy: 0.0174\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01744 to 0.01719, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0220 - binary_crossentropy: 0.0173 - val_loss: 0.0219 - val_binary_crossentropy: 0.0172\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01719 to 0.01708, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0218 - binary_crossentropy: 0.0170 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01708 to 0.01693, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0168 - val_loss: 0.0217 - val_binary_crossentropy: 0.0169\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01693 to 0.01681, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0165 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01681 to 0.01671, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0212 - binary_crossentropy: 0.0164 - val_loss: 0.0215 - val_binary_crossentropy: 0.0167\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01671 to 0.01661, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0162 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01661 to 0.01661, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01661 to 0.01650, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0213 - val_binary_crossentropy: 0.0165\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01650 to 0.01643, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0155 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy did not improve from 0.01643\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0153 - val_loss: 0.0213 - val_binary_crossentropy: 0.0165\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01643 to 0.01633, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0213 - val_binary_crossentropy: 0.0163\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy did not improve from 0.01633\n",
      "155/155 - 2s - loss: 0.0199 - binary_crossentropy: 0.0148 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01633 to 0.01629, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0197 - binary_crossentropy: 0.0147 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy did not improve from 0.01629\n",
      "155/155 - 1s - loss: 0.0195 - binary_crossentropy: 0.0145 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01629 to 0.01619, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0139 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01619 to 0.01615, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0138 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01615 to 0.01614, saving model to repeat:1_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0136 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0135 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0135 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0135 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0134 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0134 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0134 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0184 - binary_crossentropy: 0.0134 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0135 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01614\n",
      "155/155 - 1s - loss: 0.0184 - binary_crossentropy: 0.0135 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 00036: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 9\n",
      "epoch 0  | loss: 0.17879 | val_logits_ll: 0.02258 |  0:00:03s\n",
      "epoch 10 | loss: 0.01813 | val_logits_ll: 0.01792 |  0:00:35s\n",
      "epoch 20 | loss: 0.01723 | val_logits_ll: 0.01749 |  0:01:07s\n",
      "epoch 30 | loss: 0.01699 | val_logits_ll: 0.01727 |  0:01:40s\n",
      "epoch 40 | loss: 0.01673 | val_logits_ll: 0.01696 |  0:02:12s\n",
      "epoch 50 | loss: 0.01616 | val_logits_ll: 0.01639 |  0:02:44s\n",
      "epoch 60 | loss: 0.01478 | val_logits_ll: 0.01641 |  0:03:16s\n",
      "epoch 70 | loss: 0.01359 | val_logits_ll: 0.01672 |  0:03:47s\n",
      "\n",
      "Early stopping occured at epoch 77 with best_epoch = 57 and best_val_logits_ll = 0.01631\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 10\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04095, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.3501 - binary_crossentropy: 0.3490 - val_loss: 0.0436 - val_binary_crossentropy: 0.0409\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04095 to 0.02263, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0342 - binary_crossentropy: 0.0309 - val_loss: 0.0264 - val_binary_crossentropy: 0.0226\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02263 to 0.02033, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0265 - binary_crossentropy: 0.0226 - val_loss: 0.0244 - val_binary_crossentropy: 0.0203\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02033 to 0.01965, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0247 - binary_crossentropy: 0.0205 - val_loss: 0.0239 - val_binary_crossentropy: 0.0196\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01965 to 0.01853, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0230 - val_binary_crossentropy: 0.0185\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01853 to 0.01807, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0232 - binary_crossentropy: 0.0187 - val_loss: 0.0226 - val_binary_crossentropy: 0.0181\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01807 to 0.01780, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0228 - binary_crossentropy: 0.0183 - val_loss: 0.0223 - val_binary_crossentropy: 0.0178\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01780 to 0.01763, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0225 - binary_crossentropy: 0.0179 - val_loss: 0.0223 - val_binary_crossentropy: 0.0176\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01763 to 0.01737, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0223 - binary_crossentropy: 0.0176 - val_loss: 0.0220 - val_binary_crossentropy: 0.0174\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01737 to 0.01732, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0220 - binary_crossentropy: 0.0173 - val_loss: 0.0220 - val_binary_crossentropy: 0.0173\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01732 to 0.01699, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0218 - binary_crossentropy: 0.0170 - val_loss: 0.0218 - val_binary_crossentropy: 0.0170\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01699 to 0.01696, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0168 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01696 to 0.01679, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0213 - binary_crossentropy: 0.0165 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01679 to 0.01667, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0212 - binary_crossentropy: 0.0163 - val_loss: 0.0215 - val_binary_crossentropy: 0.0167\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01667 to 0.01654, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0162 - val_loss: 0.0213 - val_binary_crossentropy: 0.0165\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01654 to 0.01649, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01649 to 0.01624, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy did not improve from 0.01624\n",
      "155/155 - 1s - loss: 0.0205 - binary_crossentropy: 0.0156 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01624 to 0.01620, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy did not improve from 0.01620\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01620 to 0.01604, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0196 - binary_crossentropy: 0.0146 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01604 to 0.01598, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy did not improve from 0.01598\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy did not improve from 0.01598\n",
      "155/155 - 1s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01598 to 0.01597, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy did not improve from 0.01597\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01597 to 0.01596, saving model to repeat:1_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0161\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0161\n",
      "Epoch 37/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01596\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0161\n",
      "Epoch 00037: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=2 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAPEAT NUMBER 3 SEED 2\n",
      "TabNet\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 1\n",
      "epoch 0  | loss: 0.17833 | val_logits_ll: 0.02244 |  0:00:04s\n",
      "epoch 10 | loss: 0.01806 | val_logits_ll: 0.01757 |  0:00:38s\n",
      "epoch 20 | loss: 0.01723 | val_logits_ll: 0.01715 |  0:01:13s\n",
      "epoch 30 | loss: 0.01691 | val_logits_ll: 0.01695 |  0:01:45s\n",
      "epoch 40 | loss: 0.01675 | val_logits_ll: 0.01684 |  0:02:20s\n",
      "epoch 50 | loss: 0.01654 | val_logits_ll: 0.01691 |  0:02:53s\n",
      "epoch 60 | loss: 0.01539 | val_logits_ll: 0.0164  |  0:03:27s\n",
      "epoch 70 | loss: 0.01405 | val_logits_ll: 0.01647 |  0:04:00s\n",
      "\n",
      "Early stopping occured at epoch 77 with best_epoch = 57 and best_val_logits_ll = 0.01617\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 2\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04181, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 2s - loss: 0.3507 - binary_crossentropy: 0.3496 - val_loss: 0.0445 - val_binary_crossentropy: 0.0418\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04181 to 0.02262, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0342 - binary_crossentropy: 0.0309 - val_loss: 0.0263 - val_binary_crossentropy: 0.0226\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02262 to 0.02035, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0265 - binary_crossentropy: 0.0226 - val_loss: 0.0245 - val_binary_crossentropy: 0.0203\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02035 to 0.01905, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0247 - binary_crossentropy: 0.0205 - val_loss: 0.0234 - val_binary_crossentropy: 0.0191\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01905 to 0.01840, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0228 - val_binary_crossentropy: 0.0184\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01840 to 0.01796, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0232 - binary_crossentropy: 0.0187 - val_loss: 0.0224 - val_binary_crossentropy: 0.0180\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01796 to 0.01768, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0230 - binary_crossentropy: 0.0184 - val_loss: 0.0224 - val_binary_crossentropy: 0.0177\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01768 to 0.01741, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0179 - val_loss: 0.0220 - val_binary_crossentropy: 0.0174\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01741 to 0.01726, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0227 - binary_crossentropy: 0.0180 - val_loss: 0.0220 - val_binary_crossentropy: 0.0173\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01726 to 0.01714, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0221 - binary_crossentropy: 0.0173 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01714 to 0.01685, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0218 - binary_crossentropy: 0.0171 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01685 to 0.01677, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0168 - val_loss: 0.0215 - val_binary_crossentropy: 0.0168\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01677 to 0.01665, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01665 to 0.01657, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0212 - binary_crossentropy: 0.0163 - val_loss: 0.0213 - val_binary_crossentropy: 0.0166\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01657 to 0.01641, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0161 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01641 to 0.01639, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0160 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01639 to 0.01623, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01623 to 0.01610, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0155 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy did not improve from 0.01610\n",
      "155/155 - 2s - loss: 0.0202 - binary_crossentropy: 0.0153 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01610 to 0.01604, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy did not improve from 0.01604\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01604 to 0.01590, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0144 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01590 to 0.01589, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0143 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01589 to 0.01585, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01585 to 0.01584, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0208 - val_binary_crossentropy: 0.0158\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01584 to 0.01584, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0139 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01584 to 0.01583, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 2s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy improved from 0.01583 to 0.01583, saving model to repeat:2_Fold:1.hdf5\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0139 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0139 - val_loss: 0.0207 - val_binary_crossentropy: 0.0158\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0139 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0139 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0139 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0140 - val_loss: 0.0207 - val_binary_crossentropy: 0.0159\n",
      "Epoch 38/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00038: val_binary_crossentropy did not improve from 0.01583\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0141 - val_loss: 0.0207 - val_binary_crossentropy: 0.0160\n",
      "Epoch 00038: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 3\n",
      "epoch 0  | loss: 0.1789  | val_logits_ll: 0.02259 |  0:00:03s\n",
      "epoch 10 | loss: 0.01809 | val_logits_ll: 0.01819 |  0:00:35s\n",
      "epoch 20 | loss: 0.0171  | val_logits_ll: 0.01744 |  0:01:08s\n",
      "epoch 30 | loss: 0.01674 | val_logits_ll: 0.01708 |  0:01:40s\n",
      "epoch 40 | loss: 0.01679 | val_logits_ll: 0.01686 |  0:02:13s\n",
      "epoch 50 | loss: 0.0157  | val_logits_ll: 0.01659 |  0:02:46s\n",
      "epoch 60 | loss: 0.01463 | val_logits_ll: 0.01676 |  0:03:18s\n",
      "epoch 70 | loss: 0.01346 | val_logits_ll: 0.01727 |  0:03:52s\n",
      "\n",
      "Early stopping occured at epoch 76 with best_epoch = 56 and best_val_logits_ll = 0.01653\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 4\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04310, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.3502 - binary_crossentropy: 0.3491 - val_loss: 0.0458 - val_binary_crossentropy: 0.0431\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04310 to 0.02254, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0342 - binary_crossentropy: 0.0310 - val_loss: 0.0263 - val_binary_crossentropy: 0.0225\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02254 to 0.02023, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0263 - binary_crossentropy: 0.0224 - val_loss: 0.0243 - val_binary_crossentropy: 0.0202\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02023 to 0.01935, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0247 - binary_crossentropy: 0.0205 - val_loss: 0.0236 - val_binary_crossentropy: 0.0194\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01935 to 0.01862, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.0239 - binary_crossentropy: 0.0196 - val_loss: 0.0231 - val_binary_crossentropy: 0.0186\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01862 to 0.01805, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0226 - val_binary_crossentropy: 0.0181\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01805 to 0.01781, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0183 - val_loss: 0.0224 - val_binary_crossentropy: 0.0178\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01781 to 0.01745, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0180 - val_loss: 0.0222 - val_binary_crossentropy: 0.0175\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01745 to 0.01737, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0179 - val_loss: 0.0221 - val_binary_crossentropy: 0.0174\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01737 to 0.01709, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0222 - binary_crossentropy: 0.0174 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01709 to 0.01693, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0172 - val_loss: 0.0217 - val_binary_crossentropy: 0.0169\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01693 to 0.01683, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0217 - binary_crossentropy: 0.0169 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01683 to 0.01678, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0215 - binary_crossentropy: 0.0167 - val_loss: 0.0216 - val_binary_crossentropy: 0.0168\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01678 to 0.01665, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0212 - binary_crossentropy: 0.0163 - val_loss: 0.0214 - val_binary_crossentropy: 0.0167\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01665 to 0.01654, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0209 - binary_crossentropy: 0.0161 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01654 to 0.01649, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0160 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01649 to 0.01642, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01642 to 0.01633, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0155 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01633 to 0.01630, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 2s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01630 to 0.01622, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0201 - binary_crossentropy: 0.0151 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy did not improve from 0.01622\n",
      "155/155 - 1s - loss: 0.0199 - binary_crossentropy: 0.0149 - val_loss: 0.0212 - val_binary_crossentropy: 0.0162\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01622 to 0.01622, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0147 - val_loss: 0.0212 - val_binary_crossentropy: 0.0162\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01622 to 0.01607, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0193 - binary_crossentropy: 0.0142 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01607 to 0.01604, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01604 to 0.01604, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0139 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01604 to 0.01602, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0139 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01602 to 0.01600, saving model to repeat:2_Fold:3.hdf5\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0137 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 2s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0138 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0137 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 37/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01600\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0138 - val_loss: 0.0209 - val_binary_crossentropy: 0.0161\n",
      "Epoch 00037: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 5\n",
      "epoch 0  | loss: 0.17777 | val_logits_ll: 0.0225  |  0:00:03s\n",
      "epoch 10 | loss: 0.01822 | val_logits_ll: 0.0182  |  0:00:35s\n",
      "epoch 20 | loss: 0.01739 | val_logits_ll: 0.01749 |  0:01:09s\n",
      "epoch 30 | loss: 0.017   | val_logits_ll: 0.017   |  0:01:43s\n",
      "epoch 40 | loss: 0.01681 | val_logits_ll: 0.01693 |  0:02:16s\n",
      "epoch 50 | loss: 0.01661 | val_logits_ll: 0.01671 |  0:02:50s\n",
      "epoch 60 | loss: 0.01551 | val_logits_ll: 0.01646 |  0:03:22s\n",
      "epoch 70 | loss: 0.01443 | val_logits_ll: 0.01652 |  0:03:55s\n",
      "epoch 80 | loss: 0.01328 | val_logits_ll: 0.01684 |  0:04:28s\n",
      "\n",
      "Early stopping occured at epoch 85 with best_epoch = 65 and best_val_logits_ll = 0.01627\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 6\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04076, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 2s - loss: 0.3493 - binary_crossentropy: 0.3482 - val_loss: 0.0434 - val_binary_crossentropy: 0.0408\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04076 to 0.02242, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0341 - binary_crossentropy: 0.0308 - val_loss: 0.0261 - val_binary_crossentropy: 0.0224\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02242 to 0.02000, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0265 - binary_crossentropy: 0.0226 - val_loss: 0.0241 - val_binary_crossentropy: 0.0200\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02000 to 0.01912, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0245 - binary_crossentropy: 0.0203 - val_loss: 0.0234 - val_binary_crossentropy: 0.0191\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01912 to 0.01860, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0238 - binary_crossentropy: 0.0195 - val_loss: 0.0230 - val_binary_crossentropy: 0.0186\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01860 to 0.01808, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0226 - val_binary_crossentropy: 0.0181\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01808 to 0.01777, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0183 - val_loss: 0.0224 - val_binary_crossentropy: 0.0178\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01777 to 0.01752, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0225 - binary_crossentropy: 0.0179 - val_loss: 0.0221 - val_binary_crossentropy: 0.0175\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01752 to 0.01747, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0223 - binary_crossentropy: 0.0176 - val_loss: 0.0221 - val_binary_crossentropy: 0.0175\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01747 to 0.01719, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0221 - binary_crossentropy: 0.0174 - val_loss: 0.0219 - val_binary_crossentropy: 0.0172\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01719 to 0.01700, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0171 - val_loss: 0.0218 - val_binary_crossentropy: 0.0170\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01700 to 0.01697, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0168 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01697 to 0.01675, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0215 - val_binary_crossentropy: 0.0167\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01675 to 0.01662, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0212 - binary_crossentropy: 0.0163 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01662 to 0.01657, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0161 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy did not improve from 0.01657\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01657 to 0.01635, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0213 - val_binary_crossentropy: 0.0163\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01635 to 0.01631, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 2s - loss: 0.0203 - binary_crossentropy: 0.0154 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01631 to 0.01627, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0153 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01627 to 0.01622, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0202 - binary_crossentropy: 0.0152 - val_loss: 0.0212 - val_binary_crossentropy: 0.0162\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01622 to 0.01622, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0148 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01622 to 0.01616, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0147 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01616 to 0.01605, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0196 - binary_crossentropy: 0.0146 - val_loss: 0.0210 - val_binary_crossentropy: 0.0160\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy did not improve from 0.01605\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0143 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy did not improve from 0.01605\n",
      "155/155 - 1s - loss: 0.0192 - binary_crossentropy: 0.0141 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy did not improve from 0.01605\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0140 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01605 to 0.01592, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0135 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01592\n",
      "155/155 - 1s - loss: 0.0184 - binary_crossentropy: 0.0132 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy improved from 0.01592 to 0.01591, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0183 - binary_crossentropy: 0.0131 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy improved from 0.01591 to 0.01587, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0182 - binary_crossentropy: 0.0131 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy improved from 0.01587 to 0.01586, saving model to repeat:2_Fold:5.hdf5\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0129 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0181 - binary_crossentropy: 0.0129 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0179 - binary_crossentropy: 0.0128 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00039: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0129 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 2s - loss: 0.0180 - binary_crossentropy: 0.0130 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 41/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00041: val_binary_crossentropy did not improve from 0.01586\n",
      "155/155 - 1s - loss: 0.0180 - binary_crossentropy: 0.0130 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 00041: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 7\n",
      "epoch 0  | loss: 0.17856 | val_logits_ll: 0.02269 |  0:00:03s\n",
      "epoch 10 | loss: 0.0183  | val_logits_ll: 0.01842 |  0:00:36s\n",
      "epoch 20 | loss: 0.01731 | val_logits_ll: 0.0174  |  0:01:10s\n",
      "epoch 30 | loss: 0.01691 | val_logits_ll: 0.01732 |  0:01:42s\n",
      "epoch 40 | loss: 0.01668 | val_logits_ll: 0.01681 |  0:02:16s\n",
      "epoch 50 | loss: 0.01648 | val_logits_ll: 0.01676 |  0:02:48s\n",
      "epoch 60 | loss: 0.01552 | val_logits_ll: 0.01644 |  0:03:22s\n",
      "epoch 70 | loss: 0.01453 | val_logits_ll: 0.01657 |  0:03:54s\n",
      "\n",
      "Early stopping occured at epoch 79 with best_epoch = 59 and best_val_logits_ll = 0.01635\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 8\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.04284, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.3513 - binary_crossentropy: 0.3502 - val_loss: 0.0455 - val_binary_crossentropy: 0.0428\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.04284 to 0.02323, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0343 - binary_crossentropy: 0.0310 - val_loss: 0.0269 - val_binary_crossentropy: 0.0232\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02323 to 0.02004, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0263 - binary_crossentropy: 0.0224 - val_loss: 0.0241 - val_binary_crossentropy: 0.0200\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02004 to 0.01904, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0247 - binary_crossentropy: 0.0205 - val_loss: 0.0233 - val_binary_crossentropy: 0.0190\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01904 to 0.01843, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0239 - binary_crossentropy: 0.0195 - val_loss: 0.0229 - val_binary_crossentropy: 0.0184\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01843 to 0.01783, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0224 - val_binary_crossentropy: 0.0178\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01783 to 0.01767, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0229 - binary_crossentropy: 0.0183 - val_loss: 0.0222 - val_binary_crossentropy: 0.0177\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01767 to 0.01746, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0226 - binary_crossentropy: 0.0179 - val_loss: 0.0221 - val_binary_crossentropy: 0.0175\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01746 to 0.01735, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0223 - binary_crossentropy: 0.0176 - val_loss: 0.0220 - val_binary_crossentropy: 0.0174\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01735 to 0.01710, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0221 - binary_crossentropy: 0.0174 - val_loss: 0.0218 - val_binary_crossentropy: 0.0171\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01710 to 0.01694, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0218 - binary_crossentropy: 0.0171 - val_loss: 0.0217 - val_binary_crossentropy: 0.0169\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01694 to 0.01688, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0216 - binary_crossentropy: 0.0169 - val_loss: 0.0216 - val_binary_crossentropy: 0.0169\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01688 to 0.01675, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0215 - val_binary_crossentropy: 0.0168\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01675 to 0.01666, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0212 - binary_crossentropy: 0.0163 - val_loss: 0.0215 - val_binary_crossentropy: 0.0167\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01666 to 0.01657, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0162 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01657 to 0.01649, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0209 - binary_crossentropy: 0.0160 - val_loss: 0.0214 - val_binary_crossentropy: 0.0165\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01649 to 0.01641, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0213 - val_binary_crossentropy: 0.0164\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01641 to 0.01635, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0155 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy improved from 0.01635 to 0.01633, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0202 - binary_crossentropy: 0.0153 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01633 to 0.01628, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0201 - binary_crossentropy: 0.0151 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01628 to 0.01624, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 2s - loss: 0.0199 - binary_crossentropy: 0.0149 - val_loss: 0.0212 - val_binary_crossentropy: 0.0162\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy did not improve from 0.01624\n",
      "155/155 - 1s - loss: 0.0197 - binary_crossentropy: 0.0147 - val_loss: 0.0212 - val_binary_crossentropy: 0.0163\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy did not improve from 0.01624\n",
      "155/155 - 1s - loss: 0.0196 - binary_crossentropy: 0.0145 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01624 to 0.01611, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0138 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy did not improve from 0.01611\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0137 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy improved from 0.01611 to 0.01608, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0187 - binary_crossentropy: 0.0136 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy improved from 0.01608 to 0.01608, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy improved from 0.01608 to 0.01608, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy improved from 0.01608 to 0.01607, saving model to repeat:2_Fold:7.hdf5\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0135 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0136 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0136 - val_loss: 0.0210 - val_binary_crossentropy: 0.0161\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0136 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\n",
      "Epoch 00039: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0185 - binary_crossentropy: 0.0136 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 40/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00040: val_binary_crossentropy did not improve from 0.01607\n",
      "155/155 - 1s - loss: 0.0186 - binary_crossentropy: 0.0136 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 00040: early stopping\n",
      "Device used : cuda\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 9\n",
      "epoch 0  | loss: 0.17849 | val_logits_ll: 0.02215 |  0:00:02s\n",
      "epoch 10 | loss: 0.01804 | val_logits_ll: 0.01906 |  0:00:35s\n",
      "epoch 20 | loss: 0.01713 | val_logits_ll: 0.01952 |  0:01:08s\n",
      "epoch 30 | loss: 0.01692 | val_logits_ll: 0.01734 |  0:01:42s\n",
      "epoch 40 | loss: 0.01614 | val_logits_ll: 0.01676 |  0:02:14s\n",
      "epoch 50 | loss: 0.01543 | val_logits_ll: 0.01678 |  0:02:49s\n",
      "epoch 60 | loss: 0.01393 | val_logits_ll: 0.01686 |  0:03:21s\n",
      "epoch 70 | loss: 0.01298 | val_logits_ll: 0.01728 |  0:03:55s\n",
      "\n",
      "Early stopping occured at epoch 73 with best_epoch = 53 and best_val_logits_ll = 0.01664\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 10\n",
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.03947, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.3498 - binary_crossentropy: 0.3487 - val_loss: 0.0422 - val_binary_crossentropy: 0.0395\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.03947 to 0.02261, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0342 - binary_crossentropy: 0.0309 - val_loss: 0.0264 - val_binary_crossentropy: 0.0226\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.02261 to 0.02016, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0264 - binary_crossentropy: 0.0225 - val_loss: 0.0243 - val_binary_crossentropy: 0.0202\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.02016 to 0.01912, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0249 - binary_crossentropy: 0.0207 - val_loss: 0.0234 - val_binary_crossentropy: 0.0191\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.01912 to 0.01829, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0240 - binary_crossentropy: 0.0196 - val_loss: 0.0228 - val_binary_crossentropy: 0.0183\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.01829 to 0.01797, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0233 - binary_crossentropy: 0.0188 - val_loss: 0.0225 - val_binary_crossentropy: 0.0180\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.01797 to 0.01773, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0230 - binary_crossentropy: 0.0184 - val_loss: 0.0223 - val_binary_crossentropy: 0.0177\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.01773 to 0.01739, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0225 - binary_crossentropy: 0.0179 - val_loss: 0.0220 - val_binary_crossentropy: 0.0174\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.01739 to 0.01722, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0223 - binary_crossentropy: 0.0176 - val_loss: 0.0219 - val_binary_crossentropy: 0.0172\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy improved from 0.01722 to 0.01699, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0220 - binary_crossentropy: 0.0173 - val_loss: 0.0217 - val_binary_crossentropy: 0.0170\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy improved from 0.01699 to 0.01693, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0219 - binary_crossentropy: 0.0172 - val_loss: 0.0216 - val_binary_crossentropy: 0.0169\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.01693 to 0.01687, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.0216 - binary_crossentropy: 0.0168 - val_loss: 0.0216 - val_binary_crossentropy: 0.0169\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_binary_crossentropy improved from 0.01687 to 0.01661, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0214 - binary_crossentropy: 0.0166 - val_loss: 0.0214 - val_binary_crossentropy: 0.0166\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_binary_crossentropy improved from 0.01661 to 0.01652, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0211 - binary_crossentropy: 0.0163 - val_loss: 0.0213 - val_binary_crossentropy: 0.0165\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.01652 to 0.01643, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0210 - binary_crossentropy: 0.0161 - val_loss: 0.0212 - val_binary_crossentropy: 0.0164\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: val_binary_crossentropy improved from 0.01643 to 0.01631, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0208 - binary_crossentropy: 0.0159 - val_loss: 0.0211 - val_binary_crossentropy: 0.0163\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: val_binary_crossentropy improved from 0.01631 to 0.01623, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0206 - binary_crossentropy: 0.0157 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: val_binary_crossentropy improved from 0.01623 to 0.01621, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0204 - binary_crossentropy: 0.0154 - val_loss: 0.0211 - val_binary_crossentropy: 0.0162\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: val_binary_crossentropy did not improve from 0.01621\n",
      "155/155 - 2s - loss: 0.0202 - binary_crossentropy: 0.0153 - val_loss: 0.0211 - val_binary_crossentropy: 0.0163\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: val_binary_crossentropy improved from 0.01621 to 0.01617, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0200 - binary_crossentropy: 0.0150 - val_loss: 0.0210 - val_binary_crossentropy: 0.0162\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00021: val_binary_crossentropy improved from 0.01617 to 0.01615, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0198 - binary_crossentropy: 0.0148 - val_loss: 0.0211 - val_binary_crossentropy: 0.0161\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: val_binary_crossentropy improved from 0.01615 to 0.01599, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0194 - binary_crossentropy: 0.0143 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: val_binary_crossentropy improved from 0.01599 to 0.01599, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.0192 - binary_crossentropy: 0.0142 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: val_binary_crossentropy improved from 0.01599 to 0.01597, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0191 - binary_crossentropy: 0.0141 - val_loss: 0.0209 - val_binary_crossentropy: 0.0160\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 00025: val_binary_crossentropy improved from 0.01597 to 0.01594, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 1s - loss: 0.0190 - binary_crossentropy: 0.0140 - val_loss: 0.0209 - val_binary_crossentropy: 0.0159\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: val_binary_crossentropy improved from 0.01594 to 0.01593, saving model to repeat:2_Fold:9.hdf5\n",
      "155/155 - 2s - loss: 0.0189 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0189 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0159\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 00028: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0138 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 00031: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0139 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0139 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0139 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 00034: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0139 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0139 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 36/100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00036: val_binary_crossentropy did not improve from 0.01593\n",
      "155/155 - 1s - loss: 0.0188 - binary_crossentropy: 0.0139 - val_loss: 0.0208 - val_binary_crossentropy: 0.0160\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "models, oof_preds = make_folds(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "b7d35a42-c682-49e2-a0c6-b33a528442df",
    "_uuid": "9a8b91ee-8644-4072-b810-1c4d51913302",
    "execution": {
     "iopub.execute_input": "2020-11-05T23:57:43.582457Z",
     "iopub.status.busy": "2020-11-05T23:57:43.581564Z",
     "iopub.status.idle": "2020-11-05T23:57:49.393369Z",
     "shell.execute_reply": "2020-11-05T23:57:49.394703Z"
    },
    "papermill": {
     "duration": 6.580337,
     "end_time": "2020-11-05T23:57:49.394909",
     "exception": false,
     "start_time": "2020-11-05T23:57:42.814572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAKY RELU SCORE\n",
      "Repeat 1 OOF Log Loss: 0.01639366046410945\n",
      "LEAKY RELU SCORE\n",
      "Repeat 2 OOF Log Loss: 0.016361492525219325\n",
      "LEAKY RELU SCORE\n",
      "Repeat 3 OOF Log Loss: 0.016327601675774708\n",
      "Mean OOF Log Loss: 0.015998018015484772\n"
     ]
    }
   ],
   "source": [
    "mean_oof_preds = train_targets.copy()\n",
    "mean_oof_preds.loc[:, target_cols] = 0\n",
    "scores = []\n",
    "for i, p in enumerate(oof_preds):\n",
    "    loss = multi_log_loss(train_targets, p)\n",
    "    print(\"LEAKY RELU SCORE\")\n",
    "    print(f\"Repeat {i + 1} OOF Log Loss: {loss}\")\n",
    "    scores.append(loss)\n",
    "    mean_oof_preds.loc[:,target_cols] += p\n",
    "mean_oof_preds.loc[:, target_cols] /= len(oof_preds)\n",
    "print(f\"Mean OOF Log Loss: {multi_log_loss(train_targets, mean_oof_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.565752,
     "end_time": "2020-11-05T23:57:50.533613",
     "exception": false,
     "start_time": "2020-11-05T23:57:49.967861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T23:57:51.931479Z",
     "iopub.status.busy": "2020-11-05T23:57:51.930521Z",
     "iopub.status.idle": "2020-11-05T23:57:52.625367Z",
     "shell.execute_reply": "2020-11-05T23:57:52.624684Z"
    },
    "papermill": {
     "duration": 1.367868,
     "end_time": "2020-11-05T23:57:52.625490",
     "exception": false,
     "start_time": "2020-11-05T23:57:51.257622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ = pd.read_csv('../input/lish-moa/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T23:57:53.763566Z",
     "iopub.status.busy": "2020-11-05T23:57:53.756763Z",
     "iopub.status.idle": "2020-11-05T23:57:53.766772Z",
     "shell.execute_reply": "2020-11-05T23:57:53.767569Z"
    },
    "papermill": {
     "duration": 0.578144,
     "end_time": "2020-11-05T23:57:53.767717",
     "exception": false,
     "start_time": "2020-11-05T23:57:53.189573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sig_id = test_[test_[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "85c6e9de-4e94-47d5-a573-0d76d45adbb8",
    "_uuid": "d9b8369d-3130-4cfd-a750-41f043108434",
    "execution": {
     "iopub.execute_input": "2020-11-05T23:57:54.902827Z",
     "iopub.status.busy": "2020-11-05T23:57:54.901811Z",
     "iopub.status.idle": "2020-11-05T23:58:06.122848Z",
     "shell.execute_reply": "2020-11-05T23:58:06.121163Z"
    },
    "papermill": {
     "duration": 11.795417,
     "end_time": "2020-11-05T23:58:06.122983",
     "exception": false,
     "start_time": "2020-11-05T23:57:54.327566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = sub.copy()\n",
    "test_preds[target_cols] = 0\n",
    "test_preds = test_preds.drop(\"sig_id\", axis = 1)\n",
    "test_preds[\"sig_id\"] = sig_id\n",
    "test_preds.dropna(inplace=True)\n",
    "test_preds.drop(\"sig_id\", axis = 1, inplace=True)\n",
    "for i, model in enumerate(models):\n",
    "    if type(model) == tf.python.keras.engine.sequential.Sequential:\n",
    "        preds = model.predict(test_features.values)\n",
    "        test_preds.loc[:,target_cols] += clip(preds, p_min, p_max)\n",
    "    else:\n",
    "        preds = model.predict(test_features.values)\n",
    "        preds = 1 / (1 + np.exp(-preds))\n",
    "        test_preds.loc[:,target_cols] += clip(preds, p_min, p_max)\n",
    "test_preds.loc[:,target_cols] /= len(models)\n",
    "test_preds[\"sig_id\"] = sig_id\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "submission = pd.merge(test_features[[\"sig_id\"]], test_preds, on = \"sig_id\", how = \"left\")\n",
    "submission.fillna(0, inplace = True)\n",
    "sub = submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T23:58:07.273857Z",
     "iopub.status.busy": "2020-11-05T23:58:07.255983Z",
     "iopub.status.idle": "2020-11-05T23:58:07.295417Z",
     "shell.execute_reply": "2020-11-05T23:58:07.296054Z"
    },
    "papermill": {
     "duration": 0.597917,
     "end_time": "2020-11-05T23:58:07.296219",
     "exception": false,
     "start_time": "2020-11-05T23:58:06.698302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.023096</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.019041</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.001511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.048867</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.023858</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001125                0.001701   \n",
       "1     id_001897cda                     0.001008                0.001246   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001078                0.001050   \n",
       "4     id_0027f1083                     0.002172                0.001752   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001067                0.001316   \n",
       "3978  id_ff925dd0d                     0.003531                0.003489   \n",
       "3979  id_ffb710450                     0.001660                0.001171   \n",
       "3980  id_ffbb869f2                     0.001171                0.001458   \n",
       "3981  id_ffd5800b6                     0.001102                0.001225   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.002070                        0.016167   \n",
       "1           0.002026                        0.002671   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.002206                        0.012899   \n",
       "4           0.001930                        0.019041   \n",
       "...              ...                             ...   \n",
       "3977        0.001446                        0.003927   \n",
       "3978        0.001197                        0.009008   \n",
       "3979        0.001211                        0.013707   \n",
       "3980        0.001177                        0.024208   \n",
       "3981        0.001965                        0.017156   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.022312                        0.004645   \n",
       "1                              0.002646                        0.002649   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.016743                        0.005119   \n",
       "4                              0.023429                        0.003759   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.014576                        0.002745   \n",
       "3978                           0.025537                        0.005249   \n",
       "3979                           0.048867                        0.006277   \n",
       "3980                           0.023858                        0.006165   \n",
       "3981                           0.021115                        0.005997   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002231                       0.005575   \n",
       "1                       0.004246                       0.012346   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.002585                       0.004552   \n",
       "4                       0.006138                       0.002411   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001685                       0.003232   \n",
       "3978                    0.005611                       0.003706   \n",
       "3979                    0.003892                       0.004800   \n",
       "3980                    0.004443                       0.003147   \n",
       "3981                    0.003630                       0.005609   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.001000  ...                               0.001247   \n",
       "1                       0.005370  ...                               0.001210   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.001000  ...                               0.001040   \n",
       "4                       0.001000  ...                               0.001171   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001045  ...                               0.001032   \n",
       "3978                    0.001086  ...                               0.001002   \n",
       "3979                    0.001000  ...                               0.001002   \n",
       "3980                    0.001163  ...                               0.001000   \n",
       "3981                    0.001000  ...                               0.001078   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001885         0.003652           0.001283   \n",
       "1         0.001341         0.003430           0.001001   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001214         0.003792           0.023096   \n",
       "4         0.001037         0.003204           0.001915   \n",
       "...            ...              ...                ...   \n",
       "3977      0.004402         0.002690           0.178268   \n",
       "3978      0.001235         0.002566           0.001973   \n",
       "3979      0.001008         0.002053           0.001179   \n",
       "3980      0.001004         0.003350           0.001308   \n",
       "3981      0.002195         0.002467           0.003895   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.001053                               0.001218   \n",
       "1                      0.012034                               0.001098   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.004543                               0.001014   \n",
       "4                      0.001168                               0.001324   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.008973                               0.001063   \n",
       "3978                   0.002062                               0.001309   \n",
       "3979                   0.001625                               0.001000   \n",
       "3980                   0.001467                               0.001004   \n",
       "3981                   0.001582                               0.001065   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.001086   0.002906                    0.003658       0.002009  \n",
       "1            0.008330   0.001292                    0.004247       0.003805  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.001454   0.002057                    0.001373       0.003001  \n",
       "4            0.001122   0.001909                    0.001000       0.001558  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.004183   0.001969                    0.001363       0.001511  \n",
       "3978         0.001523   0.001523                    0.001026       0.001341  \n",
       "3979         0.001041   0.001493                    0.001020       0.001379  \n",
       "3980         0.001494   0.001702                    0.001062       0.003166  \n",
       "3981         0.001718   0.002377                    0.001046       0.001817  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "18a1cc50-0be4-4f77-8342-162b5ca2ec0f",
    "_uuid": "b91ecf02-c13e-4005-a8db-9f2b0cd86e5e",
    "execution": {
     "iopub.execute_input": "2020-11-05T23:58:08.502554Z",
     "iopub.status.busy": "2020-11-05T23:58:08.501505Z",
     "iopub.status.idle": "2020-11-05T23:58:08.537907Z",
     "shell.execute_reply": "2020-11-05T23:58:08.538504Z"
    },
    "papermill": {
     "duration": 0.630036,
     "end_time": "2020-11-05T23:58:08.538666",
     "exception": false,
     "start_time": "2020-11-05T23:58:07.908630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>sig_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.016167</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>id_0004d9e33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>id_001897cda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.023096</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>id_00276f245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.019041</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>id_0027f1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>0.039380</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.017432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>id_006fc47b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.178268</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>id_ff7004b87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>id_ff925dd0d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.048867</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>id_ffb710450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.023858</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.027715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>id_ffbb869f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>id_ffd5800b6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3624 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                        0.001125                0.001701        0.002070   \n",
       "1                        0.001008                0.001246        0.002026   \n",
       "2                        0.001078                0.001050        0.002206   \n",
       "3                        0.002172                0.001752        0.001930   \n",
       "4                        0.001137                0.001067        0.001814   \n",
       "...                           ...                     ...             ...   \n",
       "3619                     0.001067                0.001316        0.001446   \n",
       "3620                     0.003531                0.003489        0.001197   \n",
       "3621                     0.001660                0.001171        0.001211   \n",
       "3622                     0.001171                0.001458        0.001177   \n",
       "3623                     0.001102                0.001225        0.001965   \n",
       "\n",
       "      acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                           0.016167                           0.022312   \n",
       "1                           0.002671                           0.002646   \n",
       "2                           0.012899                           0.016743   \n",
       "3                           0.019041                           0.023429   \n",
       "4                           0.026640                           0.039380   \n",
       "...                              ...                                ...   \n",
       "3619                        0.003927                           0.014576   \n",
       "3620                        0.009008                           0.025537   \n",
       "3621                        0.013707                           0.048867   \n",
       "3622                        0.024208                           0.023858   \n",
       "3623                        0.017156                           0.021115   \n",
       "\n",
       "      acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                           0.004645                    0.002231   \n",
       "1                           0.002649                    0.004246   \n",
       "2                           0.005119                    0.002585   \n",
       "3                           0.003759                    0.006138   \n",
       "4                           0.006277                    0.004986   \n",
       "...                              ...                         ...   \n",
       "3619                        0.002745                    0.001685   \n",
       "3620                        0.005249                    0.005611   \n",
       "3621                        0.006277                    0.003892   \n",
       "3622                        0.006165                    0.004443   \n",
       "3623                        0.005997                    0.003630   \n",
       "\n",
       "      adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                          0.005575                    0.001000   \n",
       "1                          0.012346                    0.005370   \n",
       "2                          0.004552                    0.001000   \n",
       "3                          0.002411                    0.001000   \n",
       "4                          0.002249                    0.001000   \n",
       "...                             ...                         ...   \n",
       "3619                       0.003232                    0.001045   \n",
       "3620                       0.003706                    0.001086   \n",
       "3621                       0.004800                    0.001000   \n",
       "3622                       0.003147                    0.001163   \n",
       "3623                       0.005609                    0.001000   \n",
       "\n",
       "      adrenergic_receptor_agonist  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0                        0.012027  ...      0.001885         0.003652   \n",
       "1                        0.008353  ...      0.001341         0.003430   \n",
       "2                        0.013895  ...      0.001214         0.003792   \n",
       "3                        0.012204  ...      0.001037         0.003204   \n",
       "4                        0.017432  ...      0.001259         0.003226   \n",
       "...                           ...  ...           ...              ...   \n",
       "3619                     0.005281  ...      0.004402         0.002690   \n",
       "3620                     0.015425  ...      0.001235         0.002566   \n",
       "3621                     0.016911  ...      0.001008         0.002053   \n",
       "3622                     0.027715  ...      0.001004         0.003350   \n",
       "3623                     0.006076  ...      0.002195         0.002467   \n",
       "\n",
       "      tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0              0.001283                   0.001053   \n",
       "1              0.001001                   0.012034   \n",
       "2              0.023096                   0.004543   \n",
       "3              0.001915                   0.001168   \n",
       "4              0.005100                   0.001308   \n",
       "...                 ...                        ...   \n",
       "3619           0.178268                   0.008973   \n",
       "3620           0.001973                   0.002062   \n",
       "3621           0.001179                   0.001625   \n",
       "3622           0.001308                   0.001467   \n",
       "3623           0.003895                   0.001582   \n",
       "\n",
       "      ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                  0.001218         0.001086   0.002906   \n",
       "1                                  0.001098         0.008330   0.001292   \n",
       "2                                  0.001014         0.001454   0.002057   \n",
       "3                                  0.001324         0.001122   0.001909   \n",
       "4                                  0.001018         0.001049   0.002202   \n",
       "...                                     ...              ...        ...   \n",
       "3619                               0.001063         0.004183   0.001969   \n",
       "3620                               0.001309         0.001523   0.001523   \n",
       "3621                               0.001000         0.001041   0.001493   \n",
       "3622                               0.001004         0.001494   0.001702   \n",
       "3623                               0.001065         0.001718   0.002377   \n",
       "\n",
       "      vitamin_d_receptor_agonist  wnt_inhibitor        sig_id  \n",
       "0                       0.003658       0.002009  id_0004d9e33  \n",
       "1                       0.004247       0.003805  id_001897cda  \n",
       "2                       0.001373       0.003001  id_00276f245  \n",
       "3                       0.001000       0.001558  id_0027f1083  \n",
       "4                       0.001000       0.002282  id_006fc47b8  \n",
       "...                          ...            ...           ...  \n",
       "3619                    0.001363       0.001511  id_ff7004b87  \n",
       "3620                    0.001026       0.001341  id_ff925dd0d  \n",
       "3621                    0.001020       0.001379  id_ffb710450  \n",
       "3622                    0.001062       0.003166  id_ffbb869f2  \n",
       "3623                    0.001046       0.001817  id_ffd5800b6  \n",
       "\n",
       "[3624 rows x 207 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "c62c652f-4c90-4a01-a1d3-931c8b6edf9d",
    "_uuid": "93d6474d-7ee0-482b-9094-c47068c4e216",
    "execution": {
     "iopub.execute_input": "2020-11-05T23:58:09.768520Z",
     "iopub.status.busy": "2020-11-05T23:58:09.767521Z",
     "iopub.status.idle": "2020-11-05T23:58:09.893841Z",
     "shell.execute_reply": "2020-11-05T23:58:09.894406Z"
    },
    "papermill": {
     "duration": 0.74294,
     "end_time": "2020-11-05T23:58:09.894570",
     "exception": false,
     "start_time": "2020-11-05T23:58:09.151630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Diff(list1, list2): \n",
    "    return (list(list(set(list1)-set(list2)) + list(set(list2)-set(list1)))) \n",
    "\n",
    "Diff (submission.columns, pd.read_csv('../input/lish-moa/sample_submission.csv').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de9c971a-7604-4a7e-bec7-90e39a82fdc6",
    "_uuid": "e603f1e3-aa40-49dd-9863-19511b31a206",
    "papermill": {
     "duration": 0.587345,
     "end_time": "2020-11-05T23:58:11.037297",
     "exception": false,
     "start_time": "2020-11-05T23:58:10.449952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "683dfabd-24ea-4fcf-9569-9f0593e24aa7",
    "_uuid": "0bef53c9-1ea1-46c1-8a67-f29fa4179cf4",
    "papermill": {
     "duration": 0.553109,
     "end_time": "2020-11-05T23:58:12.145184",
     "exception": false,
     "start_time": "2020-11-05T23:58:11.592075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4421.560882,
   "end_time": "2020-11-05T23:58:14.379545",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-05T22:44:32.818663",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
